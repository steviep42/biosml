<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Using External ML Frameworks | Predictive Learning in R</title>
  <meta name="description" content="Chapter 12 Using External ML Frameworks | Predictive Learning in R" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Using External ML Frameworks | Predictive Learning in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Using External ML Frameworks | Predictive Learning in R" />
  
  
  

<meta name="author" content="Steve Pittard" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification-example.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#machine-learning"><i class="fa fa-check"></i><b>1.1</b> Machine Learning</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#predictive-modeling"><i class="fa fa-check"></i><b>1.2</b> Predictive Modeling</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#in-sample-vs-out-of-sample-data"><i class="fa fa-check"></i><b>1.3</b> In-Sample vs Out-Of-Sample Data</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#performance-metrics"><i class="fa fa-check"></i><b>1.4</b> Performance Metrics</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#black-box"><i class="fa fa-check"></i><b>1.5</b> Black Box</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html"><i class="fa fa-check"></i><b>2</b> Predictive / Supervised Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#explanation-vs-prediction"><i class="fa fa-check"></i><b>2.1</b> Explanation vs Prediction</a></li>
<li class="chapter" data-level="2.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#two-types-of-predictive-models"><i class="fa fa-check"></i><b>2.2</b> Two Types of Predictive Models:</a></li>
<li class="chapter" data-level="2.3" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#bias-vs-variance"><i class="fa fa-check"></i><b>2.3</b> Bias vs Variance</a><ul>
<li class="chapter" data-level="2.3.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#bias"><i class="fa fa-check"></i><b>2.3.1</b> Bias</a></li>
<li class="chapter" data-level="2.3.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#variance"><i class="fa fa-check"></i><b>2.3.2</b> Variance</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#overfitting-and-underfitting"><i class="fa fa-check"></i><b>2.4</b> Overfitting and Underfitting</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-motivating-example.html"><a href="a-motivating-example.html"><i class="fa fa-check"></i><b>3</b> A Motivating Example</a><ul>
<li class="chapter" data-level="3.1" data-path="a-motivating-example.html"><a href="a-motivating-example.html#suggested-workflow"><i class="fa fa-check"></i><b>3.1</b> Suggested Workflow</a></li>
<li class="chapter" data-level="3.2" data-path="a-motivating-example.html"><a href="a-motivating-example.html#scatterplot"><i class="fa fa-check"></i><b>3.2</b> Scatterplot</a></li>
<li class="chapter" data-level="3.3" data-path="a-motivating-example.html"><a href="a-motivating-example.html#correlations"><i class="fa fa-check"></i><b>3.3</b> Correlations</a></li>
<li class="chapter" data-level="3.4" data-path="a-motivating-example.html"><a href="a-motivating-example.html#building-a-model---in-sample-error"><i class="fa fa-check"></i><b>3.4</b> Building A Model - In Sample Error</a></li>
<li class="chapter" data-level="3.5" data-path="a-motivating-example.html"><a href="a-motivating-example.html#out-of-sample-data"><i class="fa fa-check"></i><b>3.5</b> Out Of Sample Data</a></li>
<li class="chapter" data-level="3.6" data-path="a-motivating-example.html"><a href="a-motivating-example.html#other-methods"><i class="fa fa-check"></i><b>3.6</b> Other Methods ?</a></li>
<li class="chapter" data-level="3.7" data-path="a-motivating-example.html"><a href="a-motivating-example.html#summary"><i class="fa fa-check"></i><b>3.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="training-test-data.html"><a href="training-test-data.html"><i class="fa fa-check"></i><b>4</b> Training / Test Data</a><ul>
<li class="chapter" data-level="4.1" data-path="training-test-data.html"><a href="training-test-data.html#cross-fold-validation"><i class="fa fa-check"></i><b>4.1</b> Cross Fold Validation</a></li>
<li class="chapter" data-level="4.2" data-path="training-test-data.html"><a href="training-test-data.html#create-a-function-to-automate-things"><i class="fa fa-check"></i><b>4.2</b> Create A Function To Automate Things</a></li>
<li class="chapter" data-level="4.3" data-path="training-test-data.html"><a href="training-test-data.html#repeated-cross-validation"><i class="fa fa-check"></i><b>4.3</b> Repeated Cross Validation</a></li>
<li class="chapter" data-level="4.4" data-path="training-test-data.html"><a href="training-test-data.html#bootstrap"><i class="fa fa-check"></i><b>4.4</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="caret-package.html"><a href="caret-package.html"><i class="fa fa-check"></i><b>5</b> Caret Package</a><ul>
<li class="chapter" data-level="5.1" data-path="caret-package.html"><a href="caret-package.html#putting-caret-to-work"><i class="fa fa-check"></i><b>5.1</b> Putting caret To Work</a></li>
<li class="chapter" data-level="5.2" data-path="caret-package.html"><a href="caret-package.html#back-to-the-beginning"><i class="fa fa-check"></i><b>5.2</b> Back To The Beginning</a></li>
<li class="chapter" data-level="5.3" data-path="caret-package.html"><a href="caret-package.html#splitting"><i class="fa fa-check"></i><b>5.3</b> Splitting</a></li>
<li class="chapter" data-level="5.4" data-path="caret-package.html"><a href="caret-package.html#calling-the-train-function"><i class="fa fa-check"></i><b>5.4</b> Calling The train() Function</a></li>
<li class="chapter" data-level="5.5" data-path="caret-package.html"><a href="caret-package.html#one-size-fits-all"><i class="fa fa-check"></i><b>5.5</b> One Size Fits All</a></li>
<li class="chapter" data-level="5.6" data-path="caret-package.html"><a href="caret-package.html#hyperparameters"><i class="fa fa-check"></i><b>5.6</b> Hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>6</b> Decision Trees</a><ul>
<li class="chapter" data-level="6.1" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>6.1</b> Advantages</a></li>
<li class="chapter" data-level="6.2" data-path="decision-trees.html"><a href="decision-trees.html#a-classification-example"><i class="fa fa-check"></i><b>6.2</b> A Classification Example</a><ul>
<li class="chapter" data-level="6.2.1" data-path="decision-trees.html"><a href="decision-trees.html#evaluating-performance"><i class="fa fa-check"></i><b>6.2.1</b> Evaluating performance</a></li>
<li class="chapter" data-level="6.2.2" data-path="decision-trees.html"><a href="decision-trees.html#tree-splitting"><i class="fa fa-check"></i><b>6.2.2</b> Tree Splitting</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="decision-trees.html"><a href="decision-trees.html#gini-index"><i class="fa fa-check"></i><b>6.3</b> Gini Index</a></li>
<li class="chapter" data-level="6.4" data-path="decision-trees.html"><a href="decision-trees.html#regression-trees"><i class="fa fa-check"></i><b>6.4</b> Regression Trees</a><ul>
<li class="chapter" data-level="6.4.1" data-path="decision-trees.html"><a href="decision-trees.html#performance-measure"><i class="fa fa-check"></i><b>6.4.1</b> Performance Measure</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="decision-trees.html"><a href="decision-trees.html#parameters-vs-hyperparameters"><i class="fa fa-check"></i><b>6.5</b> Parameters vs Hyperparameters</a></li>
<li class="chapter" data-level="6.6" data-path="decision-trees.html"><a href="decision-trees.html#grid-searching"><i class="fa fa-check"></i><b>6.6</b> Grid Searching</a></li>
<li class="chapter" data-level="6.7" data-path="decision-trees.html"><a href="decision-trees.html#bagged-trees"><i class="fa fa-check"></i><b>6.7</b> Bagged Trees</a></li>
<li class="chapter" data-level="6.8" data-path="decision-trees.html"><a href="decision-trees.html#random-forests"><i class="fa fa-check"></i><b>6.8</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html"><i class="fa fa-check"></i><b>7</b> Using Methods Other Than lm</a><ul>
<li class="chapter" data-level="7.1" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html#parameters-vs-hyperparameters-1"><i class="fa fa-check"></i><b>7.1</b> Parameters vs Hyperparameters</a></li>
<li class="chapter" data-level="7.2" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>7.2</b> Hyperparameter Tuning</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html"><i class="fa fa-check"></i><b>8</b> Picking The Best Model</a><ul>
<li class="chapter" data-level="8.1" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#using-the-resamples-function"><i class="fa fa-check"></i><b>8.1</b> Using the resamples() function</a></li>
<li class="chapter" data-level="8.2" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#model-performance"><i class="fa fa-check"></i><b>8.2</b> Model Performance</a></li>
<li class="chapter" data-level="8.3" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#feature-selection"><i class="fa fa-check"></i><b>8.3</b> Feature Selection</a><ul>
<li class="chapter" data-level="8.3.1" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#recursive-feature-elimination"><i class="fa fa-check"></i><b>8.3.1</b> Recursive Feature Elimination</a></li>
<li class="chapter" data-level="8.3.2" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#redundant-feature-removal"><i class="fa fa-check"></i><b>8.3.2</b> Redundant Feature Removal</a></li>
<li class="chapter" data-level="8.3.3" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#feature-importance"><i class="fa fa-check"></i><b>8.3.3</b> Feature Importance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>9</b> Data Pre Processing</a><ul>
<li class="chapter" data-level="9.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#types-of-pre-processing"><i class="fa fa-check"></i><b>9.1</b> Types of Pre Processing</a></li>
<li class="chapter" data-level="9.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#missing-values"><i class="fa fa-check"></i><b>9.2</b> Missing Values</a><ul>
<li class="chapter" data-level="9.2.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#finding-rows-with-missing-data"><i class="fa fa-check"></i><b>9.2.1</b> Finding Rows with Missing Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#finding-columns-with-missing-data"><i class="fa fa-check"></i><b>9.2.2</b> Finding Columns With Missing Data</a></li>
<li class="chapter" data-level="9.2.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#use-the-median-approach"><i class="fa fa-check"></i><b>9.2.3</b> Use the Median Approach</a></li>
<li class="chapter" data-level="9.2.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#package-based-approach"><i class="fa fa-check"></i><b>9.2.4</b> Package-based Approach</a></li>
<li class="chapter" data-level="9.2.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#using-caret"><i class="fa fa-check"></i><b>9.2.5</b> Using caret</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#scaling"><i class="fa fa-check"></i><b>9.3</b> Scaling</a><ul>
<li class="chapter" data-level="9.3.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#methods-that-benefit-from-scaling"><i class="fa fa-check"></i><b>9.3.1</b> Methods That Benefit From Scaling</a></li>
<li class="chapter" data-level="9.3.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#methods-that-do-not-require-scaling"><i class="fa fa-check"></i><b>9.3.2</b> Methods That Do Not Require Scaling</a></li>
<li class="chapter" data-level="9.3.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#how-to-scale"><i class="fa fa-check"></i><b>9.3.3</b> How To Scale</a></li>
<li class="chapter" data-level="9.3.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#order-of-processing"><i class="fa fa-check"></i><b>9.3.4</b> Order of Processing</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#low-variance-variables"><i class="fa fa-check"></i><b>9.4</b> Low Variance Variables</a></li>
<li class="chapter" data-level="9.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#order-of-pre-processing"><i class="fa fa-check"></i><b>9.5</b> Order of Pre-Processing</a></li>
<li class="chapter" data-level="9.6" data-path="data-pre-processing.html"><a href="data-pre-processing.html#identifying-redundant-features"><i class="fa fa-check"></i><b>9.6</b> Identifying Redundant Features</a><ul>
<li class="chapter" data-level="9.6.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#highly-correlated-variables"><i class="fa fa-check"></i><b>9.6.1</b> Highly Correlated Variables</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="data-pre-processing.html"><a href="data-pre-processing.html#ranking-features"><i class="fa fa-check"></i><b>9.7</b> Ranking Features</a></li>
<li class="chapter" data-level="9.8" data-path="data-pre-processing.html"><a href="data-pre-processing.html#feature-selection-1"><i class="fa fa-check"></i><b>9.8</b> Feature Selection</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="classification-problems.html"><a href="classification-problems.html"><i class="fa fa-check"></i><b>10</b> Classification Problems</a><ul>
<li class="chapter" data-level="10.1" data-path="classification-problems.html"><a href="classification-problems.html#performance-measures"><i class="fa fa-check"></i><b>10.1</b> Performance Measures</a></li>
<li class="chapter" data-level="10.2" data-path="classification-problems.html"><a href="classification-problems.html#important-terminology"><i class="fa fa-check"></i><b>10.2</b> Important Terminology</a></li>
<li class="chapter" data-level="10.3" data-path="classification-problems.html"><a href="classification-problems.html#a-basic-model"><i class="fa fa-check"></i><b>10.3</b> A Basic Model</a></li>
<li class="chapter" data-level="10.4" data-path="classification-problems.html"><a href="classification-problems.html#selecting-the-correct-alpha"><i class="fa fa-check"></i><b>10.4</b> Selecting The Correct Alpha</a></li>
<li class="chapter" data-level="10.5" data-path="classification-problems.html"><a href="classification-problems.html#hypothesis-testing"><i class="fa fa-check"></i><b>10.5</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="10.6" data-path="classification-problems.html"><a href="classification-problems.html#confusion-matrix"><i class="fa fa-check"></i><b>10.6</b> Confusion Matrix</a><ul>
<li class="chapter" data-level="10.6.1" data-path="classification-problems.html"><a href="classification-problems.html#computing-performance-metrics"><i class="fa fa-check"></i><b>10.6.1</b> Computing Performance Metrics</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="classification-problems.html"><a href="classification-problems.html#picking-the-right-metric"><i class="fa fa-check"></i><b>10.7</b> Picking the Right Metric</a></li>
<li class="chapter" data-level="10.8" data-path="classification-problems.html"><a href="classification-problems.html#wait.-where-are-we"><i class="fa fa-check"></i><b>10.8</b> Wait. Where Are We ?</a></li>
<li class="chapter" data-level="10.9" data-path="classification-problems.html"><a href="classification-problems.html#better-ways-to-compute-the-roc-curve"><i class="fa fa-check"></i><b>10.9</b> Better Ways To Compute The ROC Curve</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="classification-example.html"><a href="classification-example.html"><i class="fa fa-check"></i><b>11</b> Classification Example</a><ul>
<li class="chapter" data-level="11.1" data-path="classification-example.html"><a href="classification-example.html#exploratory-plots"><i class="fa fa-check"></i><b>11.1</b> Exploratory Plots</a></li>
<li class="chapter" data-level="11.2" data-path="classification-example.html"><a href="classification-example.html#generalized-linear-models"><i class="fa fa-check"></i><b>11.2</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="11.3" data-path="classification-example.html"><a href="classification-example.html#random-forests-1"><i class="fa fa-check"></i><b>11.3</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html"><i class="fa fa-check"></i><b>12</b> Using External ML Frameworks</a><ul>
<li class="chapter" data-level="12.1" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-h2o"><i class="fa fa-check"></i><b>12.1</b> Using h2o</a></li>
<li class="chapter" data-level="12.2" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#create-some-h20-models"><i class="fa fa-check"></i><b>12.2</b> Create Some h20 Models</a></li>
<li class="chapter" data-level="12.3" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#saving-a-model"><i class="fa fa-check"></i><b>12.3</b> Saving A Model</a></li>
<li class="chapter" data-level="12.4" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-the-h2o-auto-ml-feature"><i class="fa fa-check"></i><b>12.4</b> Using The h2o Auto ML Feature</a></li>
<li class="chapter" data-level="12.5" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#launching-a-job"><i class="fa fa-check"></i><b>12.5</b> Launching a Job</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Learning in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="using-external-ml-frameworks" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Using External ML Frameworks</h1>
<p>There are a number of companies that provide easy access to Machine Learning services including Google, Amazon, Data Robot, and H2o. In particular, the company <a href="https://www.h2o.ai/products/h2o/">H20.ai</a> provides frameworks for accessible Machine Learning by experts and non-experts. They promote the idea of “citizen data science” which seeks to lower barriers to participation in the world of AI. While they have a commercial product, they also provide an open source tool:</p>
<blockquote>
<p>H2O is a fully open source, distributed in-memory machine learning platform with linear scalability. H2O supports the most widely used statistical &amp; machine learning algorithms including gradient boosted machines, generalized linear models, deep learning and more.</p>
</blockquote>
<p>Moreover, H2O provides access to an “Auto ML” service that selects methods appropriate to a given data set. This is useful to help jump start ideas.</p>
<blockquote>
<p>H2O also has an industry leading AutoML functionality that automatically runs through all the algorithms and their hyperparameters to produce a leaderboard of the best models. The H2O platform is used by over 18,000 organizations globally and is extremely popular in both the R &amp; Python communities.</p>
</blockquote>
<p>Better yet, there is an <a href="https://cran.r-project.org/web/packages/h2o/index.html">R package</a> called, somewhat unimaginatively, “h2o” “which provides:</p>
<blockquote>
<p>R interface for ‘H2O’, the scalable open source machine learning platform that offers parallelized implementations of many supervised and unsupervised machine learning algorithms such as Generalized Linear Models, Gradient Boosting Machines (including XGBoost), Random Forests, Deep Neural Networks (Deep Learning), Stacked Ensembles, Naive Bayes, Cox Proportional Hazards, K-Means, PCA, Word2Vec, as well as a fully automatic machine learning algorithm (AutoML).</p>
</blockquote>
<div id="using-h2o" class="section level2">
<h2><span class="header-section-number">12.1</span> Using h2o</h2>
<p>The package must first be installed which can done using the <strong>install.packages</strong> function (or the menu in R Studio). Loading the library is done just as you would any other library.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(h2o)</code></pre></div>
<pre><code>## 
## ----------------------------------------------------------------------
## 
## Your next step is to start H2O:
##     &gt; h2o.init()
## 
## For H2O package documentation, ask for help:
##     &gt; ??h2o
## 
## After starting H2O, you can use the Web UI at http://localhost:54321
## For more information visit http://docs.h2o.ai
## 
## ----------------------------------------------------------------------</code></pre>
<pre><code>## 
## Attaching package: &#39;h2o&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     cor, sd, var</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     &amp;&amp;, %*%, %in%, ||, apply, as.factor, as.numeric, colnames,
##     colnames&lt;-, ifelse, is.character, is.factor, is.numeric, log,
##     log10, log1p, log2, round, signif, trunc</code></pre>
<p>The goal of using this library is not to replace the methods available to you in R but, just like the <strong>caret</strong> package, seeks to provide a uniform interface for a variety of underlying methods. This includes common methods including an “Auto ML” service that picks methods for you. Let’s apply h2o to our work. The underlying h2o architecture uses a “running instance” concept that can be initialized and accessed from R. You initialize it once per interactive session.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.init</span>()

H2O is not running yet, starting it now...

Note<span class="op">:</span><span class="st">  </span>In case of errors look at the following log files<span class="op">:</span>
<span class="st">    </span><span class="er">/</span>var<span class="op">/</span>folders<span class="op">/</span>wh<span class="op">/</span>z0v5hqgx3dzdfgz47lnbr_3w0000gn<span class="op">/</span>T<span class="op">/</span><span class="er">/</span>RtmpRehHby<span class="op">/</span>h2o_esteban_started_from_r.out
    <span class="op">/</span>var<span class="op">/</span>folders<span class="op">/</span>wh<span class="op">/</span>z0v5hqgx3dzdfgz47lnbr_3w0000gn<span class="op">/</span>T<span class="op">/</span><span class="er">/</span>RtmpRehHby<span class="op">/</span>h2o_esteban_started_from_r.err

java version <span class="st">&quot;1.8.0_131&quot;</span>
<span class="kw">Java</span>(TM) SE Runtime <span class="kw">Environment</span> (build <span class="fl">1.8</span>.0_<span class="dv">131</span><span class="op">-</span>b11)
Java <span class="kw">HotSpot</span>(TM) <span class="dv">64</span><span class="op">-</span>Bit Server <span class="kw">VM</span> (build <span class="fl">25.131</span><span class="op">-</span>b11, mixed mode)

Starting H2O JVM and connecting<span class="op">:</span><span class="st"> </span>.. Connection successful<span class="op">!</span>

R is connected to the H2O cluster<span class="op">:</span><span class="st"> </span>
<span class="st">    </span>H2O cluster uptime<span class="op">:</span><span class="st">         </span><span class="dv">2</span> seconds <span class="dv">577</span> milliseconds 
    H2O cluster timezone<span class="op">:</span><span class="st">       </span>America<span class="op">/</span>New_York 
    H2O data parsing timezone<span class="op">:</span><span class="st">  </span>UTC 
    H2O cluster version<span class="op">:</span><span class="st">        </span><span class="fl">3.26</span>.<span class="fl">0.2</span> 
    H2O cluster version age<span class="op">:</span><span class="st">    </span><span class="dv">5</span> months and <span class="dv">5</span> days <span class="op">!!!</span><span class="st"> </span>
<span class="st">    </span>H2O cluster name<span class="op">:</span><span class="st">           </span>H2O_started_from_R_esteban_pgj795 
    H2O cluster total nodes<span class="op">:</span><span class="st">    </span><span class="dv">1</span> 
    H2O cluster total memory<span class="op">:</span><span class="st">   </span><span class="fl">1.78</span> GB 
    H2O cluster total cores<span class="op">:</span><span class="st">    </span><span class="dv">4</span> 
    H2O cluster allowed cores<span class="op">:</span><span class="st">  </span><span class="dv">4</span> 
    H2O cluster healthy<span class="op">:</span><span class="st">        </span><span class="ot">TRUE</span> 
    H2O Connection ip<span class="op">:</span><span class="st">          </span>localhost 
    H2O Connection port<span class="op">:</span><span class="st">        </span><span class="dv">54321</span> 
    H2O Connection proxy<span class="op">:</span><span class="st">       </span><span class="ot">NA</span> 
    H2O Internal Security<span class="op">:</span><span class="st">      </span><span class="ot">FALSE</span> 
    H2O API Extensions<span class="op">:</span><span class="st">         </span>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4 
    R Version<span class="op">:</span><span class="st">                  </span>R version <span class="fl">3.5</span>.<span class="dv">3</span> (<span class="dv">2019</span><span class="op">-</span><span class="dv">03</span><span class="op">-</span><span class="dv">11</span>) 

Your H2O cluster version is too <span class="kw">old</span> (<span class="dv">5</span> months and <span class="dv">5</span> days)<span class="op">!</span>
Please download and install the latest version from http<span class="op">:</span><span class="er">//</span>h2o.ai<span class="op">/</span>download<span class="op">/</span>
Show <span class="cf">in</span> New WindowClear OutputExpand<span class="op">/</span>Collapse Output
  <span class="op">|</span><span class="er">===========================================================|</span><span class="st"> </span><span class="dv">100</span>%
Console<span class="op">~</span><span class="er">/</span>Dropbox<span class="op">/</span>ML<span class="op">/</span>bookdown<span class="op">-</span>minimal<span class="op">/</span>
Console
Terminal

R Markdown

<span class="op">~</span><span class="er">/</span>Dropbox<span class="op">/</span>ML<span class="op">/</span>bookdown<span class="op">-</span>minimal<span class="op">/</span><span class="st">  </span></code></pre></div>
<p>Once the h2o environment has been initialized then work can begin. This will take the form of using R functions provided by the h2o package to read in data and prepare it for use with various methods. Let’s repeat the regression on mtcars using h2o functions. Since mtcars is already available in the the R environment we can easily import it into h2o.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Import mtcars</span>
mtcars_h2o_df &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(mtcars)

<span class="co"># Idenitfy the variable to be predicted</span>
y &lt;-<span class="st"> &quot;mpg&quot;</span>

<span class="co"># Put the predictor names into a vector</span>
x &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">colnames</span>(mtcars_h2o_df),y)</code></pre></div>
</div>
<div id="create-some-h20-models" class="section level2">
<h2><span class="header-section-number">12.2</span> Create Some h20 Models</h2>
<p>Now let’s create some training and test data sets. We could do this ourselves using conventional R commands or helper functions from the caret package. However, the h2o package provides its own set of helpers.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">splits &lt;-<span class="st"> </span><span class="kw">h2o.splitFrame</span>(mtcars_h2o_df, <span class="dt">ratios=</span><span class="fl">0.8</span>,<span class="dt">seed=</span><span class="dv">1</span>)
train_h2o &lt;-<span class="st"> </span>splits[[<span class="dv">1</span>]]
test_h2o  &lt;-<span class="st"> </span>splits[[<span class="dv">2</span>]]

train

mpg cyl disp  hp drat    wt  qsec vs am gear carb
<span class="dv">1</span> <span class="fl">21.0</span>   <span class="dv">6</span>  <span class="dv">160</span> <span class="dv">110</span> <span class="fl">3.90</span> <span class="fl">2.620</span> <span class="fl">16.46</span>  <span class="dv">0</span>  <span class="dv">1</span>    <span class="dv">4</span>    <span class="dv">4</span>
<span class="dv">2</span> <span class="fl">21.0</span>   <span class="dv">6</span>  <span class="dv">160</span> <span class="dv">110</span> <span class="fl">3.90</span> <span class="fl">2.875</span> <span class="fl">17.02</span>  <span class="dv">0</span>  <span class="dv">1</span>    <span class="dv">4</span>    <span class="dv">4</span>
<span class="dv">3</span> <span class="fl">21.4</span>   <span class="dv">6</span>  <span class="dv">258</span> <span class="dv">110</span> <span class="fl">3.08</span> <span class="fl">3.215</span> <span class="fl">19.44</span>  <span class="dv">1</span>  <span class="dv">0</span>    <span class="dv">3</span>    <span class="dv">1</span>
<span class="dv">4</span> <span class="fl">18.7</span>   <span class="dv">8</span>  <span class="dv">360</span> <span class="dv">175</span> <span class="fl">3.15</span> <span class="fl">3.440</span> <span class="fl">17.02</span>  <span class="dv">0</span>  <span class="dv">0</span>    <span class="dv">3</span>    <span class="dv">2</span>
<span class="dv">5</span> <span class="fl">18.1</span>   <span class="dv">6</span>  <span class="dv">225</span> <span class="dv">105</span> <span class="fl">2.76</span> <span class="fl">3.460</span> <span class="fl">20.22</span>  <span class="dv">1</span>  <span class="dv">0</span>    <span class="dv">3</span>    <span class="dv">1</span>
<span class="dv">6</span> <span class="fl">14.3</span>   <span class="dv">8</span>  <span class="dv">360</span> <span class="dv">245</span> <span class="fl">3.21</span> <span class="fl">3.570</span> <span class="fl">15.84</span>  <span class="dv">0</span>  <span class="dv">0</span>    <span class="dv">3</span>    <span class="dv">4</span>

[<span class="dv">29</span> rows x <span class="dv">11</span> columns] </code></pre></div>
<p>Now let’s create a model. We’ll use the Generalized Linear Model function from h2o. It is important to note that this function is implemented from within h2o. That is, we are not in anyway using any existing R packages to do this nor are we using anything from the <strong>care</strong> package. Here we’ll request a 4-Fold, Cross Validation step as part of the model assembly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">h2o_glm_model &lt;-<span class="st"> </span><span class="kw">h2o.glm</span>(<span class="dt">y=</span>y,<span class="dt">x=</span>x,train_h2o,<span class="dt">nfolds=</span><span class="dv">4</span>)
<span class="kw">summary</span>(h2o_glm_model)

<span class="co">#</span>

 <span class="op">|</span><span class="er">===========================================================|</span><span class="st"> </span><span class="dv">100</span>%
Model Details<span class="op">:</span>
<span class="er">==============</span>

H2ORegressionModel<span class="op">:</span><span class="st"> </span>glm
Model Key<span class="op">:</span><span class="st">  </span>GLM_model_R_1577927955348_<span class="dv">1</span> 
GLM Model<span class="op">:</span><span class="st"> </span>summary
    family     link                              regularization
<span class="dv">1</span> gaussian identity Elastic <span class="kw">Net</span> (<span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">lambda =</span> <span class="fl">1.0664</span> )
  number_of_predictors_total number_of_active_predictors
<span class="dv">1</span>                         <span class="dv">10</span>                           <span class="dv">9</span>
  number_of_iterations    training_frame
<span class="dv">1</span>                    <span class="dv">1</span> RTMP_sid_bf87_<span class="dv">673</span>

H2ORegressionMetrics<span class="op">:</span><span class="st"> </span>glm
<span class="op">**</span><span class="st"> </span>Reported on training data. <span class="op">**</span>

MSE<span class="op">:</span><span class="st">  </span><span class="fl">6.185253</span>
RMSE<span class="op">:</span><span class="st">  </span><span class="fl">2.487017</span>
MAE<span class="op">:</span><span class="st">  </span><span class="fl">1.940791</span>
RMSLE<span class="op">:</span><span class="st">  </span><span class="fl">0.1135999</span>
Mean Residual Deviance <span class="op">:</span><span class="st">  </span><span class="fl">6.185253</span>
R<span class="op">^</span><span class="dv">2</span> <span class="op">:</span><span class="st">  </span><span class="fl">0.8392098</span>
Null Deviance <span class="op">:</span><span class="fl">1115.568</span>
Null D.o.F. <span class="op">:</span><span class="dv">28</span>
Residual Deviance <span class="op">:</span><span class="fl">179.3723</span>
Residual D.o.F. <span class="op">:</span><span class="dv">19</span>
AIC <span class="op">:</span><span class="fl">157.1413</span>



H2ORegressionMetrics<span class="op">:</span><span class="st"> </span>glm
<span class="op">**</span><span class="st"> </span>Reported on cross<span class="op">-</span>validation data. <span class="op">**</span>
<span class="er">**</span><span class="st"> </span><span class="dv">4</span><span class="op">-</span>fold cross<span class="op">-</span>validation on training <span class="kw">data</span> (Metrics computed <span class="cf">for</span> combined holdout predictions) <span class="op">**</span>

MSE<span class="op">:</span><span class="st">  </span><span class="fl">9.520966</span>
RMSE<span class="op">:</span><span class="st">  </span><span class="fl">3.085606</span>
MAE<span class="op">:</span><span class="st">  </span><span class="fl">2.478209</span>
RMSLE<span class="op">:</span><span class="st">  </span><span class="fl">0.1462186</span>
Mean Residual Deviance <span class="op">:</span><span class="st">  </span><span class="fl">9.520966</span>
R<span class="op">^</span><span class="dv">2</span> <span class="op">:</span><span class="st">  </span><span class="fl">0.7524955</span>
Null Deviance <span class="op">:</span><span class="fl">1194.241</span>
Null D.o.F. <span class="op">:</span><span class="dv">28</span>
Residual Deviance <span class="op">:</span><span class="fl">276.108</span>
Residual D.o.F. <span class="op">:</span><span class="dv">19</span>
AIC <span class="op">:</span><span class="fl">169.6498</span>


Cross<span class="op">-</span>Validation Metrics Summary<span class="op">:</span><span class="st"> </span>
<span class="st">                            </span>mean          sd cv_1_valid cv_2_valid
mae                    <span class="fl">2.4294133</span>   <span class="fl">0.4533141</span>  <span class="fl">3.3255308</span>  <span class="fl">2.6851656</span>
mean_residual_deviance  <span class="fl">9.431254</span>   <span class="fl">2.5729601</span>  <span class="fl">11.924386</span>  <span class="fl">13.098149</span>
mse                     <span class="fl">9.431254</span>   <span class="fl">2.5729601</span>  <span class="fl">11.924386</span>  <span class="fl">13.098149</span>
null_deviance          <span class="fl">298.56015</span>    <span class="fl">73.43793</span>   <span class="fl">429.7452</span>  <span class="fl">322.68143</span>
r2                     <span class="fl">0.7409388</span> <span class="fl">0.041704282</span>  <span class="fl">0.6850852</span> <span class="fl">0.70873845</span>
residual_deviance         <span class="fl">69.027</span>   <span class="fl">21.894964</span>  <span class="fl">107.31948</span>  <span class="fl">65.490746</span>
rmse                   <span class="fl">2.9984744</span>  <span class="fl">0.46925735</span>  <span class="fl">3.4531705</span>  <span class="fl">3.6191366</span>
rmsle                  <span class="fl">0.1363086</span> <span class="fl">0.026307607</span> <span class="fl">0.19733523</span> <span class="fl">0.13199924</span>
                       cv_3_valid cv_4_valid
mae                     <span class="fl">1.6167169</span>  <span class="fl">2.0902402</span>
mean_residual_deviance  <span class="fl">3.6748443</span>   <span class="fl">9.027636</span>
mse                     <span class="fl">3.6748443</span>   <span class="fl">9.027636</span>
null_deviance           <span class="fl">139.37894</span>  <span class="fl">302.43506</span>
r2                     <span class="fl">0.83919096</span> <span class="fl">0.73074067</span>
residual_deviance       <span class="fl">22.049067</span>   <span class="fl">81.24872</span>
rmse                    <span class="fl">1.9169884</span>  <span class="fl">3.0046024</span>
rmsle                   <span class="fl">0.0983199</span> <span class="fl">0.11758001</span>

Scoring History<span class="op">:</span><span class="st"> </span>
<span class="st">            </span>timestamp   duration iterations negative_log_likelihood
<span class="dv">1</span> <span class="dv">2020</span><span class="op">-</span><span class="dv">01</span><span class="op">-</span><span class="dv">01</span> <span class="dv">20</span><span class="op">:</span><span class="dv">21</span><span class="op">:</span><span class="dv">13</span>  <span class="fl">0.000</span> sec          <span class="dv">0</span>              <span class="fl">1115.56759</span>
  objective
<span class="dv">1</span>  <span class="fl">38.46785</span>

Variable Importances<span class="op">:</span><span class="st"> </span>(Extract with <span class="st">`</span><span class="dt">h2o.varimp</span><span class="st">`</span>) 
<span class="op">==</span><span class="er">===============================================</span>

<span class="st">   </span>variable relative_importance scaled_importance  percentage
<span class="dv">1</span>        wt          <span class="fl">1.19294625</span>        <span class="fl">1.00000000</span> <span class="fl">0.208632891</span>
<span class="dv">2</span>       cyl          <span class="fl">0.92951526</span>        <span class="fl">0.77917615</span> <span class="fl">0.162561772</span>
<span class="dv">3</span>      disp          <span class="fl">0.78424629</span>        <span class="fl">0.65740287</span> <span class="fl">0.137155861</span>
<span class="dv">4</span>        hp          <span class="fl">0.69294345</span>        <span class="fl">0.58086729</span> <span class="fl">0.121188021</span>
<span class="dv">5</span>      carb          <span class="fl">0.62287613</span>        <span class="fl">0.52213261</span> <span class="fl">0.108934035</span>
<span class="dv">6</span>        am          <span class="fl">0.55736672</span>        <span class="fl">0.46721864</span> <span class="fl">0.097477175</span>
<span class="dv">7</span>        vs          <span class="fl">0.46246830</span>        <span class="fl">0.38766902</span> <span class="fl">0.080880507</span>
<span class="dv">8</span>      drat          <span class="fl">0.45447201</span>        <span class="fl">0.38096604</span> <span class="fl">0.079482047</span>
<span class="dv">9</span>      gear          <span class="fl">0.02108593</span>        <span class="fl">0.01767551</span> <span class="fl">0.003687692</span>
<span class="dv">10</span>     qsec          <span class="fl">0.00000000</span>        <span class="fl">0.00000000</span> <span class="fl">0.000000000</span></code></pre></div>
<p>Now we can do a prediction on the object against the test set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(h2o_glm_preds &lt;-<span class="st"> </span><span class="kw">h2o.predict</span>(h2o_glm_model,test_h2o))

<span class="co">#</span>
<span class="kw">h2o.performance</span>(h2o_glm_model,test_h2o)

 <span class="op">|</span><span class="er">===========================================================|</span><span class="st"> </span><span class="dv">100</span>%
   predict
<span class="dv">1</span> <span class="fl">25.93186</span>
<span class="dv">2</span> <span class="fl">20.67344</span>
<span class="dv">3</span> <span class="fl">24.38237</span>

[<span class="dv">3</span> rows x <span class="dv">1</span> column] 
H2ORegressionMetrics<span class="op">:</span><span class="st"> </span>glm

MSE<span class="op">:</span><span class="st">  </span><span class="fl">6.762548</span>
RMSE<span class="op">:</span><span class="st">  </span><span class="fl">2.60049</span>
MAE<span class="op">:</span><span class="st">  </span><span class="fl">2.495891</span>
RMSLE<span class="op">:</span><span class="st">  </span><span class="fl">0.1076563</span>
Mean Residual Deviance <span class="op">:</span><span class="st">  </span><span class="fl">6.762548</span>
R<span class="op">^</span><span class="dv">2</span> <span class="op">:</span><span class="st">  </span><span class="op">-</span><span class="fl">2.052306</span>
Null Deviance <span class="op">:</span><span class="fl">10.87611</span>
Null D.o.F. <span class="op">:</span><span class="dv">2</span>
Residual Deviance <span class="op">:</span><span class="fl">20.28765</span>
Residual D.o.F. <span class="op">:-</span><span class="dv">7</span>
AIC <span class="op">:</span><span class="fl">36.24783</span></code></pre></div>
</div>
<div id="saving-a-model" class="section level2">
<h2><span class="header-section-number">12.3</span> Saving A Model</h2>
<p>You can save the contents of any h2o generated model by using the <strong>h2o.saveModel()</strong> function. You could extract pieces of information from the S4 object but saving the model is easy to do - as is reading it back in.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_path &lt;-<span class="st"> </span><span class="kw">h2o.saveModel</span>(h2o_glm_model,<span class="dt">path=</span><span class="kw">getwd</span>(),<span class="dt">force=</span><span class="ot">TRUE</span>)

<span class="co"># If you need to load a previously saved model</span>

saved_model &lt;-<span class="st"> </span><span class="kw">h2o.loadModel</span>(model_path)</code></pre></div>
</div>
<div id="using-the-h2o-auto-ml-feature" class="section level2">
<h2><span class="header-section-number">12.4</span> Using The h2o Auto ML Feature</h2>
<p>Are you curious as to what model might be the “best” for your data ? This is a very fertile field of research that keeps growing and some feel will one be the dominant technology in ML - where a model picks a model. Sounds odd but that is where it is heading. Check the current <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html#automl-interface">h2o Auto ML documentation</a> for more details. For now, most of the Auto ML services use a set of heuristics to examine data and then find the most appropriate method to build a model. The currently supported method implementations in the opensource version include:</p>
<ul>
<li>three pre-specified XGBoost GBM (Gradient Boosting Machine) models</li>
<li>a fixed grid of GLMs, a default Random Forest (DRF)</li>
<li>five pre-specified H2O GBMs</li>
<li>a near-default Deep Neural Net</li>
<li>an Extremely Randomized Forest (XRT)</li>
<li>a random grid of XGBoost GBMs</li>
<li>a random grid of H2O GBMs</li>
<li>a random grid of Deep Neural Nets.</li>
</ul>
</div>
<div id="launching-a-job" class="section level2">
<h2><span class="header-section-number">12.5</span> Launching a Job</h2>
<p>Of course, it all begins with the idea of specifying a performance metric such as RMSE or the area under a ROC curve. The idea here is that we specify some input, apply transformations, create a test/train pair, and then call the h2o auto function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">h2o_auto_mtcars &lt;-<span class="st"> </span><span class="kw">h2o.automl</span>(<span class="dt">y =</span> y, <span class="dt">x =</span> x,
                              <span class="dt">training_frame =</span> train_h2o,
                              <span class="dt">leaderboard_frame =</span> test_h2o,
                              <span class="dt">max_runtime_secs =</span> <span class="dv">60</span>,
                              <span class="dt">seed =</span> <span class="dv">1</span>,
                              <span class="dt">sort_metric =</span> <span class="st">&quot;RMSE&quot;</span>,
                              <span class="dt">project_name =</span> <span class="st">&quot;mtcars&quot;</span>)</code></pre></div>
<p>Let’s check out the object that is returned. It is an S4 object in R which means that it has “slots” which can be accessed via the “@” operator.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">slotNames</span>(h2o_auto_mtcars)
h2o_auto_mtcars<span class="op">@</span>leaderboard

[<span class="dv">1</span>] <span class="st">&quot;project_name&quot;</span>  <span class="st">&quot;leader&quot;</span>        <span class="st">&quot;leaderboard&quot;</span>   <span class="st">&quot;event_log&quot;</span>    
[<span class="dv">5</span>] <span class="st">&quot;training_info&quot;</span>
                                        model_id
<span class="dv">1</span>     GBM_grid_1_AutoML_20200101_202413_model_<span class="dv">53</span>
<span class="dv">2</span>          DeepLearning_1_AutoML_20200101_<span class="dv">202413</span>
<span class="dv">3</span> XGBoost_grid_1_AutoML_20200101_202413_model_<span class="dv">14</span>
<span class="dv">4</span>  XGBoost_grid_1_AutoML_20200101_202413_model_<span class="dv">5</span>
<span class="dv">5</span>     GBM_grid_1_AutoML_20200101_202413_model_<span class="dv">52</span>
<span class="dv">6</span>     GBM_grid_1_AutoML_20200101_202413_model_<span class="dv">16</span>
  mean_residual_deviance      rmse       mse       mae      rmsle
<span class="dv">1</span>              <span class="fl">0.2147231</span> <span class="fl">0.4633822</span> <span class="fl">0.2147231</span> <span class="fl">0.4138704</span> <span class="fl">0.02128094</span>
<span class="dv">2</span>              <span class="fl">0.3734735</span> <span class="fl">0.6111248</span> <span class="fl">0.3734735</span> <span class="fl">0.5076945</span> <span class="fl">0.02559229</span>
<span class="dv">3</span>              <span class="fl">0.4586288</span> <span class="fl">0.6772213</span> <span class="fl">0.4586288</span> <span class="fl">0.6318582</span> <span class="fl">0.03060372</span>
<span class="dv">4</span>              <span class="fl">0.4787276</span> <span class="fl">0.6919014</span> <span class="fl">0.4787276</span> <span class="fl">0.5760670</span> <span class="fl">0.03091116</span>
<span class="dv">5</span>              <span class="fl">0.7571985</span> <span class="fl">0.8701716</span> <span class="fl">0.7571985</span> <span class="fl">0.7831136</span> <span class="fl">0.03729489</span>
<span class="dv">6</span>              <span class="fl">0.7772694</span> <span class="fl">0.8816289</span> <span class="fl">0.7772694</span> <span class="fl">0.8020415</span> <span class="fl">0.03896093</span>

[<span class="dv">89</span> rows x <span class="dv">6</span> columns] </code></pre></div>
<p>Stop the H2O instance</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.shutdown</span>(<span class="dt">prompt=</span><span class="ot">FALSE</span>)</code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification-example.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
