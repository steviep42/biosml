<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Predictive / Supervised Learning | Predictive Learning in R - BIOS 534</title>
  <meta name="description" content="Chapter 2 Predictive / Supervised Learning | Predictive Learning in R - BIOS 534" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Predictive / Supervised Learning | Predictive Learning in R - BIOS 534" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Predictive / Supervised Learning | Predictive Learning in R - BIOS 534" />
  
  
  

<meta name="author" content="Steve Pittard" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="a-motivating-example-linear-regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html"><i class="fa fa-check"></i><b>2</b> Predictive / Supervised Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#explanation-vs-prediction"><i class="fa fa-check"></i><b>2.1</b> Explanation vs Prediction</a></li>
<li class="chapter" data-level="2.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#two-types-of-predictive-models"><i class="fa fa-check"></i><b>2.2</b> Two Types of Predictive Models:</a></li>
<li class="chapter" data-level="2.3" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#bias-vs-variance"><i class="fa fa-check"></i><b>2.3</b> Bias vs Variance</a></li>
<li class="chapter" data-level="2.4" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#overfitting-and-underfitting"><i class="fa fa-check"></i><b>2.4</b> Overfitting and Underfitting</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-motivating-example-linear-regression.html"><a href="a-motivating-example-linear-regression.html"><i class="fa fa-check"></i><b>3</b> A Motivating Example - Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="a-motivating-example-linear-regression.html"><a href="a-motivating-example-linear-regression.html#scatterplot"><i class="fa fa-check"></i><b>3.1</b> Scatterplot</a></li>
<li class="chapter" data-level="3.2" data-path="a-motivating-example-linear-regression.html"><a href="a-motivating-example-linear-regression.html#correlations"><i class="fa fa-check"></i><b>3.2</b> Correlations</a></li>
<li class="chapter" data-level="3.3" data-path="a-motivating-example-linear-regression.html"><a href="a-motivating-example-linear-regression.html#building-a-model---in-sample-error"><i class="fa fa-check"></i><b>3.3</b> Building A Model - In Sample Error</a></li>
<li class="chapter" data-level="3.4" data-path="a-motivating-example-linear-regression.html"><a href="a-motivating-example-linear-regression.html#out-of-sample-data"><i class="fa fa-check"></i><b>3.4</b> Out Of Sample Data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="training-test-data.html"><a href="training-test-data.html"><i class="fa fa-check"></i><b>4</b> Training / Test Data</a><ul>
<li class="chapter" data-level="4.1" data-path="training-test-data.html"><a href="training-test-data.html#cross-fold-validation-continued"><i class="fa fa-check"></i><b>4.1</b> Cross Fold Validation Continued</a></li>
<li class="chapter" data-level="4.2" data-path="training-test-data.html"><a href="training-test-data.html#create-a-function-to-automate-things"><i class="fa fa-check"></i><b>4.2</b> Create A Function To Automate Things</a></li>
<li class="chapter" data-level="4.3" data-path="training-test-data.html"><a href="training-test-data.html#repeated-cross-validation"><i class="fa fa-check"></i><b>4.3</b> Repeated Cross Validation</a></li>
<li class="chapter" data-level="4.4" data-path="training-test-data.html"><a href="training-test-data.html#bootstrap"><i class="fa fa-check"></i><b>4.4</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html"><i class="fa fa-check"></i><b>5</b> Using Methods Other Than lm</a><ul>
<li class="chapter" data-level="5.1" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html#parameters-vs-hyperparameters"><i class="fa fa-check"></i><b>5.1</b> Parameters vs Hyperparameters</a></li>
<li class="chapter" data-level="5.2" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>5.2</b> Hyperparameter Tuning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="caret-package.html"><a href="caret-package.html"><i class="fa fa-check"></i><b>6</b> Caret Package</a><ul>
<li class="chapter" data-level="6.1" data-path="caret-package.html"><a href="caret-package.html#putting-caret-to-work"><i class="fa fa-check"></i><b>6.1</b> Putting caret To Work</a></li>
<li class="chapter" data-level="6.2" data-path="caret-package.html"><a href="caret-package.html#back-to-the-beginning"><i class="fa fa-check"></i><b>6.2</b> Back To The Beginning</a></li>
<li class="chapter" data-level="6.3" data-path="caret-package.html"><a href="caret-package.html#splitting"><i class="fa fa-check"></i><b>6.3</b> Splitting</a></li>
<li class="chapter" data-level="6.4" data-path="caret-package.html"><a href="caret-package.html#one-size-fits-all"><i class="fa fa-check"></i><b>6.4</b> One Size Fits All</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html"><i class="fa fa-check"></i><b>7</b> Picking The Best Model</a><ul>
<li class="chapter" data-level="7.1" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#using-the-resamples-function"><i class="fa fa-check"></i><b>7.1</b> Using the resamples() function</a></li>
<li class="chapter" data-level="7.2" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#model-performance"><i class="fa fa-check"></i><b>7.2</b> Model Performance</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>8</b> Data Pre Processing</a><ul>
<li class="chapter" data-level="8.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#look-for-highly-correlated-variables"><i class="fa fa-check"></i><b>8.1</b> Look for Highly Correlated Variables</a></li>
<li class="chapter" data-level="8.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#scaling-considerations"><i class="fa fa-check"></i><b>8.2</b> Scaling Considerations</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="classification-problems.html"><a href="classification-problems.html"><i class="fa fa-check"></i><b>9</b> Classification Problems</a><ul>
<li class="chapter" data-level="9.1" data-path="classification-problems.html"><a href="classification-problems.html#correlations-1"><i class="fa fa-check"></i><b>9.1</b> Correlations</a></li>
<li class="chapter" data-level="9.2" data-path="classification-problems.html"><a href="classification-problems.html#boxplots-and-densities"><i class="fa fa-check"></i><b>9.2</b> Boxplots And Densities</a></li>
<li class="chapter" data-level="9.3" data-path="classification-problems.html"><a href="classification-problems.html#generalized-linear-models"><i class="fa fa-check"></i><b>9.3</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="9.4" data-path="classification-problems.html"><a href="classification-problems.html#random-forests"><i class="fa fa-check"></i><b>9.4</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html"><i class="fa fa-check"></i><b>10</b> Using External ML Frameworks</a><ul>
<li class="chapter" data-level="10.1" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-h2o"><i class="fa fa-check"></i><b>10.1</b> Using H2o</a></li>
<li class="chapter" data-level="10.2" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#create-some-h20-models"><i class="fa fa-check"></i><b>10.2</b> Create Some h20 Models</a></li>
<li class="chapter" data-level="10.3" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#saving-a-model"><i class="fa fa-check"></i><b>10.3</b> Saving A Model</a></li>
<li class="chapter" data-level="10.4" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-the-h2o-auto-ml-feature"><i class="fa fa-check"></i><b>10.4</b> Using The h2o Auto ML Feature</a></li>
<li class="chapter" data-level="10.5" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#launching-a-job"><i class="fa fa-check"></i><b>10.5</b> Launching a Job</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Learning in R - BIOS 534</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="predictive-supervised-learning" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Predictive / Supervised Learning</h1>
<p>In Predictive Learning it is customary to apply methods to build models on existing data to help you 1) understand the data at hand and 2) maybe build a model to predict outcomes on related information</p>
<p>Of course, number 2 assumes that what you already know is suitable for application to a more general situation when this might not be the case.</p>
<div id="explanation-vs-prediction" class="section level2">
<h2><span class="header-section-number">2.1</span> Explanation vs Prediction</h2>
<p>Sometimes you just want to build a model (apply a method) to <strong>explain</strong> the data at hand as opposed to using it to predict outcomes for incoming data of a related nature. Not all models need to be predictive and in fact it might be useful to first get a basic understanding of the data before attempting to extend it to new information.</p>
<blockquote>
<p>“A common misconception in various scientific fieldsis that predictive power can be inferred from explana-tory power. However, the two are different and should be assessed separately.”</p>
<p>— Gamit Shmueli - “To Explain or Predict”</p>
</blockquote>
<p>Given a data set, there might be some variable therein that you would like to predict in terms of other variables. Ideally you would like to automate this process but not at the expense of understanding the underlying statistical considerations. The process should also be done in a way that allows one to define a specific performance measure / metric that can then be used to compare performance across a number of “models”.</p>
</div>
<div id="two-types-of-predictive-models" class="section level2">
<h2><span class="header-section-number">2.2</span> Two Types of Predictive Models:</h2>
<p>In this lecture we’ll be focusing on the following situations. In Supervised Learning we have known outcomes that can be leveraged in the creation of a model(s) that can then be used to predict labels for new data sets.</p>
<ul>
<li>For Quantitative Data, we’ll consider Regression</li>
<li>For Qualitative Data, we’ll consider Classification</li>
</ul>
<p>As previously mentioned, we will need metrics to evaluate performance of any models we build. For Regression, we’ll use Root Mean Square Error (RMSE). The formula looks like the following where P represents a vector of predictions and O represents a vector of the observed (true) values.</p>
<p><span class="math display">\[
RMSE = \sqrt\frac{\sum_i^n(P_i-O_i)^2}{n}
\]</span></p>
<p>For Classification, we’ll use measures derived from a <strong>Confusion Matrix</strong> in conjunction with a <strong>ROC Curve</strong>. We’ll discuss this in greater detail in a later section.</p>
</div>
<div id="bias-vs-variance" class="section level2">
<h2><span class="header-section-number">2.3</span> Bias vs Variance</h2>
<p>See <a href="https://thatdatatho.com/2018/08/08/explaining-bias-variance-trade-off-machine-learning/">this blog</a> for more information.</p>
<p>Think of the term <strong>bias</strong> as meaning <strong>deviation from the truth or reality</strong>. If a model fits some data very well then deviations from the actual values will be small which is what you might expect when applying the model to the very data used to produce it. You are able to <strong>explain</strong> the data but not then be able to use it to predict outcomes without experiencing large variance.</p>
<p>Any performance metric that is computed on the data “as is” will typically be somewhat optimistic in the context of predictive utility. The model you build on some data might fit the data very well (low bias) but then does not do very well when applied to a new data set wherein the model exhibits large variance.</p>
</div>
<div id="overfitting-and-underfitting" class="section level2">
<h2><span class="header-section-number">2.4</span> Overfitting and Underfitting</h2>
<p>If we <strong>overfit</strong> some data we then undermine our ability to apply it to new data in a way that results in good performance. This is the case where we have high model bias and resulting high variability when it is applied to new data. If you do “too good of a job” of learning some data then you might actually be unknowingly modeling inherent sources of error.</p>
<div class="figure">
<img src="pics/nobias.png" />

</div>
<p>If we <strong>underfit</strong> some data then consider that we haven’t “learned enough” from it to ensure low bias (deviations from reality). On the other hand if the model does a “good enough job” of describing the data then maybe it’s not a big deal especially since, when applied to new data, it doesn’t exhibit a high degree of variance.</p>
<p>Simpler models, such as linear regression, can be like this - easy to understand but somewhat biased in their assessment of data. Depending on the size of the data it might be computationally less expensive to build more biased models.</p>
<div class="figure">
<img src="pics/more_bias.png" />

</div>
<p>Models that are biased generally have less variability when applied to new data whereas less biased models generally have higher variability when applied to new data. Obviously, striking a balance between the two is desirable. There are techniques to help with this.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="a-motivating-example-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
