<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Training / Test Data | Predictive Learning in R</title>
  <meta name="description" content="Chapter 5 Training / Test Data | Predictive Learning in R" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Training / Test Data | Predictive Learning in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Training / Test Data | Predictive Learning in R" />
  
  
  

<meta name="author" content="Steve Pittard" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="decision-trees.html"/>
<link rel="next" href="using-methods-other-than-lm.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html"><i class="fa fa-check"></i><b>2</b> Predictive / Supervised Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#explanation-vs-prediction"><i class="fa fa-check"></i><b>2.1</b> Explanation vs Prediction</a><ul>
<li class="chapter" data-level="2.1.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#differences"><i class="fa fa-check"></i><b>2.1.1</b> Differences</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#two-types-of-predictive-models"><i class="fa fa-check"></i><b>2.2</b> Two Types of Predictive Models:</a></li>
<li class="chapter" data-level="2.3" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#bias-vs-variance"><i class="fa fa-check"></i><b>2.3</b> Bias vs Variance</a><ul>
<li class="chapter" data-level="2.3.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#bias"><i class="fa fa-check"></i><b>2.3.1</b> Bias</a></li>
<li class="chapter" data-level="2.3.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#variance"><i class="fa fa-check"></i><b>2.3.2</b> Variance</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#overfitting-and-underfitting"><i class="fa fa-check"></i><b>2.4</b> Overfitting and Underfitting</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-motivating-example.html"><a href="a-motivating-example.html"><i class="fa fa-check"></i><b>3</b> A Motivating Example</a><ul>
<li class="chapter" data-level="3.1" data-path="a-motivating-example.html"><a href="a-motivating-example.html#suggested-workflow"><i class="fa fa-check"></i><b>3.1</b> Suggested Workflow</a></li>
<li class="chapter" data-level="3.2" data-path="a-motivating-example.html"><a href="a-motivating-example.html#scatterplot"><i class="fa fa-check"></i><b>3.2</b> Scatterplot</a></li>
<li class="chapter" data-level="3.3" data-path="a-motivating-example.html"><a href="a-motivating-example.html#correlations"><i class="fa fa-check"></i><b>3.3</b> Correlations</a></li>
<li class="chapter" data-level="3.4" data-path="a-motivating-example.html"><a href="a-motivating-example.html#building-a-model---in-sample-error"><i class="fa fa-check"></i><b>3.4</b> Building A Model - In Sample Error</a></li>
<li class="chapter" data-level="3.5" data-path="a-motivating-example.html"><a href="a-motivating-example.html#out-of-sample-data"><i class="fa fa-check"></i><b>3.5</b> Out Of Sample Data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>4</b> Decision Trees</a><ul>
<li class="chapter" data-level="4.1" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>4.1</b> Advantages</a></li>
<li class="chapter" data-level="4.2" data-path="decision-trees.html"><a href="decision-trees.html#a-classification-example"><i class="fa fa-check"></i><b>4.2</b> A Classification Example</a><ul>
<li class="chapter" data-level="4.2.1" data-path="decision-trees.html"><a href="decision-trees.html#evaluating-performance"><i class="fa fa-check"></i><b>4.2.1</b> Evaluating performance</a></li>
<li class="chapter" data-level="4.2.2" data-path="decision-trees.html"><a href="decision-trees.html#tree-splitting"><i class="fa fa-check"></i><b>4.2.2</b> Tree Splitting</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="decision-trees.html"><a href="decision-trees.html#gini-index"><i class="fa fa-check"></i><b>4.3</b> Gini Index</a></li>
<li class="chapter" data-level="4.4" data-path="decision-trees.html"><a href="decision-trees.html#regression-trees"><i class="fa fa-check"></i><b>4.4</b> Regression Trees</a><ul>
<li class="chapter" data-level="4.4.1" data-path="decision-trees.html"><a href="decision-trees.html#performance-measure"><i class="fa fa-check"></i><b>4.4.1</b> Performance Measure</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="decision-trees.html"><a href="decision-trees.html#parameters-vs-hyperparameters"><i class="fa fa-check"></i><b>4.5</b> Parameters vs Hyperparameters</a></li>
<li class="chapter" data-level="4.6" data-path="decision-trees.html"><a href="decision-trees.html#grid-searching"><i class="fa fa-check"></i><b>4.6</b> Grid Searching</a></li>
<li class="chapter" data-level="4.7" data-path="decision-trees.html"><a href="decision-trees.html#bagged-trees"><i class="fa fa-check"></i><b>4.7</b> Bagged Trees</a></li>
<li class="chapter" data-level="4.8" data-path="decision-trees.html"><a href="decision-trees.html#random-forests"><i class="fa fa-check"></i><b>4.8</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="training-test-data.html"><a href="training-test-data.html"><i class="fa fa-check"></i><b>5</b> Training / Test Data</a><ul>
<li class="chapter" data-level="5.1" data-path="training-test-data.html"><a href="training-test-data.html#cross-fold-validation-continued"><i class="fa fa-check"></i><b>5.1</b> Cross Fold Validation Continued</a></li>
<li class="chapter" data-level="5.2" data-path="training-test-data.html"><a href="training-test-data.html#create-a-function-to-automate-things"><i class="fa fa-check"></i><b>5.2</b> Create A Function To Automate Things</a></li>
<li class="chapter" data-level="5.3" data-path="training-test-data.html"><a href="training-test-data.html#repeated-cross-validation"><i class="fa fa-check"></i><b>5.3</b> Repeated Cross Validation</a></li>
<li class="chapter" data-level="5.4" data-path="training-test-data.html"><a href="training-test-data.html#bootstrap"><i class="fa fa-check"></i><b>5.4</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html"><i class="fa fa-check"></i><b>6</b> Using Methods Other Than lm</a><ul>
<li class="chapter" data-level="6.1" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html#parameters-vs-hyperparameters-1"><i class="fa fa-check"></i><b>6.1</b> Parameters vs Hyperparameters</a></li>
<li class="chapter" data-level="6.2" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>6.2</b> Hyperparameter Tuning</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="caret-package.html"><a href="caret-package.html"><i class="fa fa-check"></i><b>7</b> Caret Package</a><ul>
<li class="chapter" data-level="7.1" data-path="caret-package.html"><a href="caret-package.html#putting-caret-to-work"><i class="fa fa-check"></i><b>7.1</b> Putting caret To Work</a></li>
<li class="chapter" data-level="7.2" data-path="caret-package.html"><a href="caret-package.html#back-to-the-beginning"><i class="fa fa-check"></i><b>7.2</b> Back To The Beginning</a></li>
<li class="chapter" data-level="7.3" data-path="caret-package.html"><a href="caret-package.html#splitting"><i class="fa fa-check"></i><b>7.3</b> Splitting</a></li>
<li class="chapter" data-level="7.4" data-path="caret-package.html"><a href="caret-package.html#one-size-fits-all"><i class="fa fa-check"></i><b>7.4</b> One Size Fits All</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html"><i class="fa fa-check"></i><b>8</b> Picking The Best Model</a><ul>
<li class="chapter" data-level="8.1" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#using-the-resamples-function"><i class="fa fa-check"></i><b>8.1</b> Using the resamples() function</a></li>
<li class="chapter" data-level="8.2" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#model-performance"><i class="fa fa-check"></i><b>8.2</b> Model Performance</a></li>
<li class="chapter" data-level="8.3" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#feature-selection"><i class="fa fa-check"></i><b>8.3</b> Feature Selection</a><ul>
<li class="chapter" data-level="8.3.1" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#recursive-feature-elimination"><i class="fa fa-check"></i><b>8.3.1</b> Recursive Feature Elimination</a></li>
<li class="chapter" data-level="8.3.2" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#redundant-feature-removal"><i class="fa fa-check"></i><b>8.3.2</b> Redundant Feature Removal</a></li>
<li class="chapter" data-level="8.3.3" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#feature-importance"><i class="fa fa-check"></i><b>8.3.3</b> Feature Importance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>9</b> Data Pre Processing</a><ul>
<li class="chapter" data-level="9.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#types-of-pre-processing"><i class="fa fa-check"></i><b>9.1</b> Types of Pre Processing</a></li>
<li class="chapter" data-level="9.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#missing-values"><i class="fa fa-check"></i><b>9.2</b> Missing Values</a><ul>
<li class="chapter" data-level="9.2.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#finding-rows-with-missing-data"><i class="fa fa-check"></i><b>9.2.1</b> Finding Rows with Missing Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#finding-columns-with-missing-data"><i class="fa fa-check"></i><b>9.2.2</b> Finding Columns With Missing Data</a></li>
<li class="chapter" data-level="9.2.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#use-the-median-approach"><i class="fa fa-check"></i><b>9.2.3</b> Use the Median Approach</a></li>
<li class="chapter" data-level="9.2.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#package-based-approach"><i class="fa fa-check"></i><b>9.2.4</b> Package-based Approach</a></li>
<li class="chapter" data-level="9.2.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#using-caret"><i class="fa fa-check"></i><b>9.2.5</b> Using caret</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#scaling"><i class="fa fa-check"></i><b>9.3</b> Scaling</a><ul>
<li class="chapter" data-level="9.3.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#methods-that-benefit-from-scaling"><i class="fa fa-check"></i><b>9.3.1</b> Methods That Benefit From Scaling</a></li>
<li class="chapter" data-level="9.3.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#methods-that-do-not-require-scaling"><i class="fa fa-check"></i><b>9.3.2</b> Methods That Do Not Require Scaling</a></li>
<li class="chapter" data-level="9.3.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#how-to-scale"><i class="fa fa-check"></i><b>9.3.3</b> How To Scale</a></li>
<li class="chapter" data-level="9.3.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#order-of-processing"><i class="fa fa-check"></i><b>9.3.4</b> Order of Processing</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#low-variance-variables"><i class="fa fa-check"></i><b>9.4</b> Low Variance Variables</a></li>
<li class="chapter" data-level="9.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#order-of-pre-processing"><i class="fa fa-check"></i><b>9.5</b> Order of Pre-Processing</a></li>
<li class="chapter" data-level="9.6" data-path="data-pre-processing.html"><a href="data-pre-processing.html#identifying-redundant-features"><i class="fa fa-check"></i><b>9.6</b> Identifying Redundant Features</a><ul>
<li class="chapter" data-level="9.6.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#highly-correlated-variables"><i class="fa fa-check"></i><b>9.6.1</b> Highly Correlated Variables</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="data-pre-processing.html"><a href="data-pre-processing.html#ranking-features"><i class="fa fa-check"></i><b>9.7</b> Ranking Features</a></li>
<li class="chapter" data-level="9.8" data-path="data-pre-processing.html"><a href="data-pre-processing.html#feature-selection-1"><i class="fa fa-check"></i><b>9.8</b> Feature Selection</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="classification-problems.html"><a href="classification-problems.html"><i class="fa fa-check"></i><b>10</b> Classification Problems</a><ul>
<li class="chapter" data-level="10.1" data-path="classification-problems.html"><a href="classification-problems.html#hypothesis-testing"><i class="fa fa-check"></i><b>10.1</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="10.1.1" data-path="classification-problems.html"><a href="classification-problems.html#type-i-and-ii-errors"><i class="fa fa-check"></i><b>10.1.1</b> Type I and II Errors</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="classification-problems.html"><a href="classification-problems.html#performance-measures"><i class="fa fa-check"></i><b>10.2</b> Performance Measures</a></li>
<li class="chapter" data-level="10.3" data-path="classification-problems.html"><a href="classification-problems.html#table-of-outcomes"><i class="fa fa-check"></i><b>10.3</b> Table of Outcomes</a><ul>
<li class="chapter" data-level="10.3.1" data-path="classification-problems.html"><a href="classification-problems.html#computing-performance-metrics"><i class="fa fa-check"></i><b>10.3.1</b> Computing Performance Metrics</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="classification-problems.html"><a href="classification-problems.html#picking-the-right-metric"><i class="fa fa-check"></i><b>10.4</b> Picking the Right Metric</a><ul>
<li class="chapter" data-level="10.4.1" data-path="classification-problems.html"><a href="classification-problems.html#working-with-prediction-probabilities"><i class="fa fa-check"></i><b>10.4.1</b> Working With Prediction Probabilities</a></li>
<li class="chapter" data-level="10.4.2" data-path="classification-problems.html"><a href="classification-problems.html#creating-a-roc-curve"><i class="fa fa-check"></i><b>10.4.2</b> Creating a ROC Curve</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="classification-example.html"><a href="classification-example.html"><i class="fa fa-check"></i><b>11</b> Classification Example</a><ul>
<li class="chapter" data-level="11.1" data-path="classification-example.html"><a href="classification-example.html#boxplots-and-densities"><i class="fa fa-check"></i><b>11.1</b> Boxplots And Densities</a></li>
<li class="chapter" data-level="11.2" data-path="classification-example.html"><a href="classification-example.html#generalized-linear-models"><i class="fa fa-check"></i><b>11.2</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="11.3" data-path="classification-example.html"><a href="classification-example.html#random-forests-1"><i class="fa fa-check"></i><b>11.3</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html"><i class="fa fa-check"></i><b>12</b> Using External ML Frameworks</a><ul>
<li class="chapter" data-level="12.1" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-h2o"><i class="fa fa-check"></i><b>12.1</b> Using h2o</a></li>
<li class="chapter" data-level="12.2" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#create-some-h20-models"><i class="fa fa-check"></i><b>12.2</b> Create Some h20 Models</a></li>
<li class="chapter" data-level="12.3" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#saving-a-model"><i class="fa fa-check"></i><b>12.3</b> Saving A Model</a></li>
<li class="chapter" data-level="12.4" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-the-h2o-auto-ml-feature"><i class="fa fa-check"></i><b>12.4</b> Using The h2o Auto ML Feature</a></li>
<li class="chapter" data-level="12.5" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#launching-a-job"><i class="fa fa-check"></i><b>12.5</b> Launching a Job</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Learning in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="training-test-data" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Training / Test Data</h1>
<p><a href="https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf" class="uri">https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf</a></p>
<blockquote>
<p>Predictive power is assessed using metrics computedfrom a holdout set or using cross-validation (Stone,1974; Geisser,1975)</p>
</blockquote>
<blockquote>
<p>Testing the procedure on the data that gaveit birth is almost certain to overestimate performance”(Mosteller and Tukey,1977).</p>
</blockquote>
<p>Let’s extend this idea of training and test splits. To increase the usefulness of a model we can take a single data set and partition / split it into a number of subsets. We just did that, but only once. We can then train the model on one of the splits (or combined splits) and then test it out on one of the unused subsets. This can help avoid over fitting.</p>
<p>In our case - what would the RMSE look like if we created say K number of subsets of the data frame and selectively held out each of the K subsets, built a model on the combined remaining subsets, and then tested the model on the holdout ? We would then average the RMSE to get an idea of its variation. The series of sequential steps would be as follows:</p>
<pre><code>Subset the data frame into k groups 
For each subset:
   Consider the subset as a &quot;hold out&quot;&quot; or test data set
   Combine the remaining subsets as a training data set
   Fit a model on the combined training set 
   Evaluate the model using the holdout test set
   Save the evaluation score (e.g. RNSE)

Summarize evaluation score (e.g. mean of RMSE)</code></pre>
<p>This is called Cross Validation. Here is the general idea in illustrated form relative to mtcars. Assume we want 4 folds. We would divide the data frame into 4 folds of 8 records each. The first model would be built using Fold 1 as the holdout / test data set <strong>after</strong> first combining Folds 2,3 and 4 into a training set set</p>
<div class="figure">
<img src="pics/cv1.png" />

</div>
<p>So the second iteration would then take the second fold as the holdout / test data frame and combine Folds 1,3, and 4 into a training data frame.</p>
<div class="figure">
<img src="pics/cv2.png" />

</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generates Some Folds</span>

num.of.folds &lt;-<span class="st"> </span><span class="dv">8</span>

<span class="co"># This generates 8 groups of 4 indices such that each</span>
<span class="co"># group has unique observations. No observation is used</span>
<span class="co"># more than once - although we could use bootstrapping</span>

folds &lt;-<span class="st"> </span><span class="kw">split</span>(<span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(mtcars)),<span class="dv">1</span><span class="op">:</span>num.of.folds) 

<span class="co"># We should have 32 indicies across the 8 groups </span>
<span class="kw">sum</span>(<span class="kw">sapply</span>(folds,length))</code></pre></div>
<pre><code>## [1] 32</code></pre>
<p>Check out the folds to get a better understanding of what is going on. Remember that each with K-fold</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">folds</code></pre></div>
<pre><code>## $`1`
## [1] 28  3 23 17
## 
## $`2`
## [1] 32 25 10 27
## 
## $`3`
## [1]  1 12  9 20
## 
## $`4`
## [1] 15  7 26  2
## 
## $`5`
## [1]  6 11 21 31
## 
## $`6`
## [1] 13  8 16 14
## 
## $`7`
## [1] 18 24 19 30
## 
## $`8`
## [1] 22 29  5  4</code></pre>
<p>Each list element has the indices of four unique observations from the data frame. We have eight folds with four elements each for a total of 32 numbers corresponding to row numbers from the mtcars data frame.</p>
<div id="cross-fold-validation-continued" class="section level2">
<h2><span class="header-section-number">5.1</span> Cross Fold Validation Continued</h2>
<p>To implement the cross validation, we will create a processing loop that will execute once for each of the 8 folds. During each execution of the loop we will create a model using data combined from all folds <strong>except</strong> the fold corresponding to the current loop number (e.g, 1, 2, .. 8).</p>
<p>Once the model is built we then test it on the fold number corresponding to the current loop number.</p>
<p>So now we can create some lists to contain the models that we make along withe the associated predictions, errors and computed RMSE. We we can inspect any of the intermediate results after the fact to validate our work or look more closely at any specific result.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Next we setup some blank lists to stash results</span>
folddf    &lt;-<span class="st"> </span><span class="kw">list</span>()  <span class="co"># Contains folds</span>
modl      &lt;-<span class="st"> </span><span class="kw">list</span>()  <span class="co"># Hold each of the K models</span>
predl     &lt;-<span class="st"> </span><span class="kw">list</span>()  <span class="co"># Hold rach of the K predictions</span>
rmse      &lt;-<span class="st"> </span><span class="kw">list</span>()  <span class="co"># Hold the computed rmse for a given model</span>

<span class="co"># Now, for each of the 8 subgroups of holdout data we will </span>
<span class="co"># create a lda model based on all the data *except* the </span>
<span class="co"># holdout group</span>

<span class="cf">for</span> (ii <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(folds)) {
  
  <span class="co"># This list holds the actual model we create for each of the </span>
  <span class="co"># 10 folds</span>
  
  modl[[ii]] &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">formula =</span> myform, 
                   <span class="dt">data =</span> mtcars[<span class="op">-</span>folds[[ii]],] 
                )
  
  <span class="co"># This list will contain / hold the models build on the fold</span>
  
  predl[[ii]]  &lt;-<span class="st"> </span><span class="kw">predict</span>(modl[[ii]],
                          <span class="dt">newdata=</span>mtcars[folds[[ii]],],
                          <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
  
  <span class="co"># This list will hold the results of the confusion matrix </span>
  <span class="co"># function. This obkect will contain info on the </span>
  <span class="co"># accuracy,  sensitivity/recall, specificity</span>
  <span class="co"># and so on for each model per fold</span>
  
    errors &lt;-<span class="st"> </span>predl[[ii]]<span class="op">-</span>mtcars[folds[[ii]],]<span class="op">$</span>mpg
    rmse[[ii]] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>(errors<span class="op">^</span><span class="dv">2</span>))
}</code></pre></div>
<p>The above list structures allow us to drill down into any aspect of the models and predictions we have made for each of the 8 folds. More importantly we can see how well the model works against each of the individual holdout / test data sets. In the end, we just want to be able to look at the average RMSE across the folds. This gives us clues as to how good the model might perform against new data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rmse &lt;-<span class="st"> </span><span class="kw">unlist</span>(rmse)
lattice<span class="op">::</span><span class="kw">dotplot</span>(rmse,
                 <span class="dt">main=</span><span class="st">&quot;RMSE Across Folds Using K-Fold CV&quot;</span>)</code></pre></div>
<p><img src="biosml_files/figure-html/latticeplot-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(rmse)</code></pre></div>
<pre><code>## [1] 3.021514</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(rmse)</code></pre></div>
<pre><code>## [1] 1.089556</code></pre>
</div>
<div id="create-a-function-to-automate-things" class="section level2">
<h2><span class="header-section-number">5.2</span> Create A Function To Automate Things</h2>
<p>Since we have gone to the trouble of creating a loop structure to process the folds, we could easily turn this into a function to automate the splitting of the data frame across some arbitrary number of folds just to get an idea of how the RMSE looks for different numbers of folds. We could even have our function accommodate different formula if we wanted but we won’t focus on that right now. You will soon discover that the <strong>caret</strong> package does these kinds of things for you but we aren’t quite there yet.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">make_mtcars_model &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">formula=</span>myform, <span class="dt">num_of_folds=</span><span class="dv">8</span>) {
  folds &lt;-<span class="st"> </span><span class="kw">split</span>(<span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(mtcars)),<span class="dv">1</span><span class="op">:</span>num_of_folds) 
  
  modl      &lt;-<span class="st"> </span><span class="kw">list</span>()
  predl     &lt;-<span class="st"> </span><span class="kw">list</span>()
  rmse      &lt;-<span class="st"> </span><span class="kw">list</span>()

  <span class="co"># Now, for each of the 10 subgroups of holdout data we will </span>
  <span class="co"># create a lda model based on all the data *except* the </span>
  <span class="co"># holdout group</span>

  <span class="cf">for</span> (ii <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(folds)) {
  
  <span class="co"># This list holds the actual model we create for each of the folds</span>
  
  modl[[ii]] &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">formula =</span> myform, 
                   <span class="dt">data =</span> mtcars[<span class="op">-</span>folds[[ii]],] 
                )
  
  <span class="co"># This list will contain / hold the models build on the fold</span>
  
  predl[[ii]]  &lt;-<span class="st"> </span><span class="kw">predict</span>(modl[[ii]],
                          <span class="dt">newdata=</span>mtcars[folds[[ii]],],
                          <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
  
  <span class="co"># Let&#39;s compute the RMSE and save it</span>
  
    errors &lt;-<span class="st"> </span>predl[[ii]]<span class="op">-</span>mtcars[folds[[ii]],]<span class="op">$</span>mpg
    rmse[[ii]] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>(errors<span class="op">^</span><span class="dv">2</span>))
  }
  <span class="kw">return</span>(<span class="dt">rmse=</span><span class="kw">unlist</span>(rmse))
}</code></pre></div>
<p><a href="HTTP://stat.cmu.edu/~brian/724/week11/lec27-bootstrap.pdf" class="uri">HTTP://stat.cmu.edu/~brian/724/week11/lec27-bootstrap.pdf</a></p>
<p>Let’s look at the average RMSE across 4 folds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">num_of_folds &lt;-<span class="st"> </span><span class="dv">4</span>

rmse &lt;-<span class="st"> </span><span class="kw">make_mtcars_model</span>(num_of_folds)

title &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;RMSE Across&quot;</span>,num_of_folds,
               <span class="st">&quot;folds - &quot;</span>,<span class="kw">as.character</span>(<span class="kw">deparse</span>(myform)),<span class="dt">sep=</span><span class="st">&quot; &quot;</span>)


<span class="kw">print</span>(<span class="kw">mean</span>(rmse))</code></pre></div>
<pre><code>## [1] 3.065706</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lattice<span class="op">::</span><span class="kw">dotplot</span>(rmse,
                 <span class="dt">main=</span><span class="st">&quot;RMSE Across Folds Using K-Fold CV&quot;</span>)</code></pre></div>
<p><img src="biosml_files/figure-html/fourfold-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(rmse)</code></pre></div>
<pre><code>## [1] 1.105896</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boxplot</span>(rmse,<span class="dt">main=</span>title)</code></pre></div>
<p><img src="biosml_files/figure-html/fourfold-2.png" width="672" /></p>
</div>
<div id="repeated-cross-validation" class="section level2">
<h2><span class="header-section-number">5.3</span> Repeated Cross Validation</h2>
<p>Since we already have an existing function we can up the ante by repeating the cross validation. This will provide more data on how the RMSE might be distributed across multiple runs, each of which does Cross Fold validation. This example will repeat a 4 Fold Cross Validation , 20 times.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">num_of_folds &lt;-<span class="st"> </span><span class="dv">4</span>

<span class="co"># Just to be clear - here is what happens when we call the function</span>
<span class="co"># once. We get back 4 RMSE values - one for each fold</span>

(rmse &lt;-<span class="st"> </span><span class="kw">make_mtcars_model</span>(num_of_folds))</code></pre></div>
<pre><code>## [1] 3.916496 2.504094 1.473652 5.182321 2.125961 4.353108 3.032338 2.382515</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Now we repeat this some number of times - like 10. So we get back</span>
<span class="co"># 80 RMSE values </span>

repeated_cv_rmse &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,make_mtcars_model)

<span class="kw">boxplot</span>(repeated_cv_rmse, 
        <span class="dt">main=</span><span class="st">&quot;RMSE Across 20 Repeats of 4 CV Folds&quot;</span>)</code></pre></div>
<p><img src="biosml_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">title &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;RMSE Across&quot;</span>,num_of_folds,
               <span class="st">&quot;folds - &quot;</span>,<span class="kw">as.character</span>(<span class="kw">deparse</span>(myform)),<span class="dt">sep=</span><span class="st">&quot; &quot;</span>)

repeated_cv_rmse &lt;-<span class="st"> </span><span class="kw">as.vector</span>(repeated_cv_rmse)
<span class="kw">boxplot</span>(repeated_cv_rmse)</code></pre></div>
<p><img src="biosml_files/figure-html/unnamed-chunk-40-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(repeated_cv_rmse)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.8665  2.1211  2.7089  3.0141  4.0634  6.1182</code></pre>
</div>
<div id="bootstrap" class="section level2">
<h2><span class="header-section-number">5.4</span> Bootstrap</h2>
<p>An alternative to K-Fold Cross Validation is to use the bootstrap sampling approach which will produce training data sets the same size as the original data set although some observations might be repeated as the sampling process is done with replacement. The observations that do not appear in each of the training sets are then used as a test set. These observations are known as “out of bag samples”. We’ll make a function to do bootstrap sampling.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">make_mtcars_boot &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">formula=</span>myform, <span class="dt">num_of_folds=</span><span class="dv">8</span>) {

  modl      &lt;-<span class="st"> </span><span class="kw">list</span>()
  predl     &lt;-<span class="st"> </span><span class="kw">list</span>()
  rmse      &lt;-<span class="st"> </span><span class="kw">list</span>()

  <span class="co"># Now, for each of the 10 subgroups of holdout data we will </span>
  <span class="co"># create a lda model based on all the data *except* the </span>
  <span class="co"># holdout group</span>

  <span class="cf">for</span> (ii <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(folds)) {
  
    training_boot_idx &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(mtcars),<span class="dt">replace=</span><span class="ot">TRUE</span>)
    test_boot_idx &lt;-<span class="st"> </span><span class="op">!</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">32</span> <span class="op">%in%</span><span class="st"> </span>training_boot_idx)
    
  <span class="co"># This list holds the actual model we create for each of the folds</span>
  
  modl[[ii]] &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">formula =</span> myform, 
                   <span class="dt">data =</span> mtcars[training_boot_idx,] 
                )
  
  <span class="co"># This list will contain / hold the models build on the fold</span>
  
  predl[[ii]]  &lt;-<span class="st"> </span><span class="kw">predict</span>(modl[[ii]],
                          <span class="dt">newdata=</span>mtcars[test_boot_idx,],
                          <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
  
  <span class="co"># Let&#39;s compute the RMSE and save it</span>
  
    errors &lt;-<span class="st"> </span>predl[[ii]]<span class="op">-</span>mtcars[test_boot_idx,]<span class="op">$</span>mpg
    rmse[[ii]] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>(errors<span class="op">^</span><span class="dv">2</span>))
  }
  <span class="kw">return</span>(<span class="dt">rmse=</span><span class="kw">unlist</span>(rmse))
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">num_of_folds &lt;-<span class="st"> </span><span class="dv">8</span>

<span class="co"># Just to be clear - here is what happens when we call the function</span>
<span class="co"># once. We get back 8 RMSE values - one for each fold</span>
(rmse &lt;-<span class="st"> </span><span class="kw">make_mtcars_boot</span>(num_of_folds))</code></pre></div>
<pre><code>## [1] 3.119174 2.414302 4.645848 2.976377 2.588440 3.407563 2.854666 4.638947</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Now we repeat this some number of times - like 10. So we get back</span>
<span class="co"># 80 RMSE values </span>

repeated_rmse &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,make_mtcars_boot)

<span class="kw">boxplot</span>(repeated_rmse,<span class="dt">main=</span><span class="st">&quot;RMSE Across 20 Repeats of 4 Boostrap Folds&quot;</span>)</code></pre></div>
<p><img src="biosml_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">title &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;RMSE Across&quot;</span>,num_of_folds,
               <span class="st">&quot;folds - &quot;</span>,<span class="kw">as.character</span>(<span class="kw">deparse</span>(myform)),<span class="dt">sep=</span><span class="st">&quot; &quot;</span>)

boot_repeated_rmse &lt;-<span class="st"> </span><span class="kw">as.vector</span>(repeated_rmse)
<span class="kw">boxplot</span>(boot_repeated_rmse)</code></pre></div>
<p><img src="biosml_files/figure-html/unnamed-chunk-42-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># How does the RMSE from the boostrap approach compare to the </span>
<span class="co"># K-Fold CV approach ? </span>

<span class="kw">print</span>(<span class="st">&quot;Summary of Bootstrap RMSE&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;Summary of Bootstrap RMSE&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(boot_repeated_rmse)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.681   2.917   3.246   3.273   3.576   5.595</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="st">&quot;Summary of CV&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;Summary of CV&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(repeated_cv_rmse)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.8665  2.1211  2.7089  3.0141  4.0634  6.1182</code></pre>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="decision-trees.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="using-methods-other-than-lm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
