<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Classification Problems | Predictive Learning in R</title>
  <meta name="description" content="Chapter 10 Classification Problems | Predictive Learning in R" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Classification Problems | Predictive Learning in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Classification Problems | Predictive Learning in R" />
  
  
  

<meta name="author" content="Steve Pittard" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-pre-processing.html"/>
<link rel="next" href="classification-example.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#machine-learning"><i class="fa fa-check"></i><b>1.1</b> Machine Learning</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#predictive-modeling"><i class="fa fa-check"></i><b>1.2</b> Predictive Modeling</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#in-sample-vs-out-of-sample-data"><i class="fa fa-check"></i><b>1.3</b> In-Sample vs Out-Of-Sample Data</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#performance-metrics"><i class="fa fa-check"></i><b>1.4</b> Performance Metrics</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#black-box"><i class="fa fa-check"></i><b>1.5</b> Black Box</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html"><i class="fa fa-check"></i><b>2</b> Predictive / Supervised Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#explanation-vs-prediction"><i class="fa fa-check"></i><b>2.1</b> Explanation vs Prediction</a><ul>
<li class="chapter" data-level="2.1.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#differences"><i class="fa fa-check"></i><b>2.1.1</b> Differences</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#two-types-of-predictive-models"><i class="fa fa-check"></i><b>2.2</b> Two Types of Predictive Models:</a></li>
<li class="chapter" data-level="2.3" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#bias-vs-variance"><i class="fa fa-check"></i><b>2.3</b> Bias vs Variance</a><ul>
<li class="chapter" data-level="2.3.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#bias"><i class="fa fa-check"></i><b>2.3.1</b> Bias</a></li>
<li class="chapter" data-level="2.3.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#variance"><i class="fa fa-check"></i><b>2.3.2</b> Variance</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#overfitting-and-underfitting"><i class="fa fa-check"></i><b>2.4</b> Overfitting and Underfitting</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-motivating-example.html"><a href="a-motivating-example.html"><i class="fa fa-check"></i><b>3</b> A Motivating Example</a><ul>
<li class="chapter" data-level="3.1" data-path="a-motivating-example.html"><a href="a-motivating-example.html#suggested-workflow"><i class="fa fa-check"></i><b>3.1</b> Suggested Workflow</a></li>
<li class="chapter" data-level="3.2" data-path="a-motivating-example.html"><a href="a-motivating-example.html#scatterplot"><i class="fa fa-check"></i><b>3.2</b> Scatterplot</a></li>
<li class="chapter" data-level="3.3" data-path="a-motivating-example.html"><a href="a-motivating-example.html#correlations"><i class="fa fa-check"></i><b>3.3</b> Correlations</a></li>
<li class="chapter" data-level="3.4" data-path="a-motivating-example.html"><a href="a-motivating-example.html#building-a-model---in-sample-error"><i class="fa fa-check"></i><b>3.4</b> Building A Model - In Sample Error</a></li>
<li class="chapter" data-level="3.5" data-path="a-motivating-example.html"><a href="a-motivating-example.html#out-of-sample-data"><i class="fa fa-check"></i><b>3.5</b> Out Of Sample Data</a></li>
<li class="chapter" data-level="3.6" data-path="a-motivating-example.html"><a href="a-motivating-example.html#other-methods"><i class="fa fa-check"></i><b>3.6</b> Other Methods ?</a></li>
<li class="chapter" data-level="3.7" data-path="a-motivating-example.html"><a href="a-motivating-example.html#summary"><i class="fa fa-check"></i><b>3.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="training-test-data.html"><a href="training-test-data.html"><i class="fa fa-check"></i><b>4</b> Training / Test Data</a><ul>
<li class="chapter" data-level="4.1" data-path="training-test-data.html"><a href="training-test-data.html#cross-fold-validation"><i class="fa fa-check"></i><b>4.1</b> Cross Fold Validation</a></li>
<li class="chapter" data-level="4.2" data-path="training-test-data.html"><a href="training-test-data.html#create-a-function-to-automate-things"><i class="fa fa-check"></i><b>4.2</b> Create A Function To Automate Things</a></li>
<li class="chapter" data-level="4.3" data-path="training-test-data.html"><a href="training-test-data.html#repeated-cross-validation"><i class="fa fa-check"></i><b>4.3</b> Repeated Cross Validation</a></li>
<li class="chapter" data-level="4.4" data-path="training-test-data.html"><a href="training-test-data.html#bootstrap"><i class="fa fa-check"></i><b>4.4</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="caret-package.html"><a href="caret-package.html"><i class="fa fa-check"></i><b>5</b> Caret Package</a><ul>
<li class="chapter" data-level="5.1" data-path="caret-package.html"><a href="caret-package.html#putting-caret-to-work"><i class="fa fa-check"></i><b>5.1</b> Putting caret To Work</a></li>
<li class="chapter" data-level="5.2" data-path="caret-package.html"><a href="caret-package.html#back-to-the-beginning"><i class="fa fa-check"></i><b>5.2</b> Back To The Beginning</a></li>
<li class="chapter" data-level="5.3" data-path="caret-package.html"><a href="caret-package.html#splitting"><i class="fa fa-check"></i><b>5.3</b> Splitting</a></li>
<li class="chapter" data-level="5.4" data-path="caret-package.html"><a href="caret-package.html#calling-the-train-function"><i class="fa fa-check"></i><b>5.4</b> Calling The train() Function</a></li>
<li class="chapter" data-level="5.5" data-path="caret-package.html"><a href="caret-package.html#one-size-fits-all"><i class="fa fa-check"></i><b>5.5</b> One Size Fits All</a></li>
<li class="chapter" data-level="5.6" data-path="caret-package.html"><a href="caret-package.html#hyperparameters"><i class="fa fa-check"></i><b>5.6</b> Hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>6</b> Decision Trees</a><ul>
<li class="chapter" data-level="6.1" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>6.1</b> Advantages</a></li>
<li class="chapter" data-level="6.2" data-path="decision-trees.html"><a href="decision-trees.html#a-classification-example"><i class="fa fa-check"></i><b>6.2</b> A Classification Example</a><ul>
<li class="chapter" data-level="6.2.1" data-path="decision-trees.html"><a href="decision-trees.html#evaluating-performance"><i class="fa fa-check"></i><b>6.2.1</b> Evaluating performance</a></li>
<li class="chapter" data-level="6.2.2" data-path="decision-trees.html"><a href="decision-trees.html#tree-splitting"><i class="fa fa-check"></i><b>6.2.2</b> Tree Splitting</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="decision-trees.html"><a href="decision-trees.html#gini-index"><i class="fa fa-check"></i><b>6.3</b> Gini Index</a></li>
<li class="chapter" data-level="6.4" data-path="decision-trees.html"><a href="decision-trees.html#regression-trees"><i class="fa fa-check"></i><b>6.4</b> Regression Trees</a><ul>
<li class="chapter" data-level="6.4.1" data-path="decision-trees.html"><a href="decision-trees.html#performance-measure"><i class="fa fa-check"></i><b>6.4.1</b> Performance Measure</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="decision-trees.html"><a href="decision-trees.html#parameters-vs-hyperparameters"><i class="fa fa-check"></i><b>6.5</b> Parameters vs Hyperparameters</a></li>
<li class="chapter" data-level="6.6" data-path="decision-trees.html"><a href="decision-trees.html#grid-searching"><i class="fa fa-check"></i><b>6.6</b> Grid Searching</a></li>
<li class="chapter" data-level="6.7" data-path="decision-trees.html"><a href="decision-trees.html#bagged-trees"><i class="fa fa-check"></i><b>6.7</b> Bagged Trees</a></li>
<li class="chapter" data-level="6.8" data-path="decision-trees.html"><a href="decision-trees.html#random-forests"><i class="fa fa-check"></i><b>6.8</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html"><i class="fa fa-check"></i><b>7</b> Using Methods Other Than lm</a><ul>
<li class="chapter" data-level="7.1" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html#parameters-vs-hyperparameters-1"><i class="fa fa-check"></i><b>7.1</b> Parameters vs Hyperparameters</a></li>
<li class="chapter" data-level="7.2" data-path="using-methods-other-than-lm.html"><a href="using-methods-other-than-lm.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>7.2</b> Hyperparameter Tuning</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html"><i class="fa fa-check"></i><b>8</b> Picking The Best Model</a><ul>
<li class="chapter" data-level="8.1" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#using-the-resamples-function"><i class="fa fa-check"></i><b>8.1</b> Using the resamples() function</a></li>
<li class="chapter" data-level="8.2" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#model-performance"><i class="fa fa-check"></i><b>8.2</b> Model Performance</a></li>
<li class="chapter" data-level="8.3" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#feature-selection"><i class="fa fa-check"></i><b>8.3</b> Feature Selection</a><ul>
<li class="chapter" data-level="8.3.1" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#recursive-feature-elimination"><i class="fa fa-check"></i><b>8.3.1</b> Recursive Feature Elimination</a></li>
<li class="chapter" data-level="8.3.2" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#redundant-feature-removal"><i class="fa fa-check"></i><b>8.3.2</b> Redundant Feature Removal</a></li>
<li class="chapter" data-level="8.3.3" data-path="picking-the-best-model.html"><a href="picking-the-best-model.html#feature-importance"><i class="fa fa-check"></i><b>8.3.3</b> Feature Importance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>9</b> Data Pre Processing</a><ul>
<li class="chapter" data-level="9.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#types-of-pre-processing"><i class="fa fa-check"></i><b>9.1</b> Types of Pre Processing</a></li>
<li class="chapter" data-level="9.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#missing-values"><i class="fa fa-check"></i><b>9.2</b> Missing Values</a><ul>
<li class="chapter" data-level="9.2.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#finding-rows-with-missing-data"><i class="fa fa-check"></i><b>9.2.1</b> Finding Rows with Missing Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#finding-columns-with-missing-data"><i class="fa fa-check"></i><b>9.2.2</b> Finding Columns With Missing Data</a></li>
<li class="chapter" data-level="9.2.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#use-the-median-approach"><i class="fa fa-check"></i><b>9.2.3</b> Use the Median Approach</a></li>
<li class="chapter" data-level="9.2.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#package-based-approach"><i class="fa fa-check"></i><b>9.2.4</b> Package-based Approach</a></li>
<li class="chapter" data-level="9.2.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#using-caret"><i class="fa fa-check"></i><b>9.2.5</b> Using caret</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#scaling"><i class="fa fa-check"></i><b>9.3</b> Scaling</a><ul>
<li class="chapter" data-level="9.3.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#methods-that-benefit-from-scaling"><i class="fa fa-check"></i><b>9.3.1</b> Methods That Benefit From Scaling</a></li>
<li class="chapter" data-level="9.3.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#methods-that-do-not-require-scaling"><i class="fa fa-check"></i><b>9.3.2</b> Methods That Do Not Require Scaling</a></li>
<li class="chapter" data-level="9.3.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#how-to-scale"><i class="fa fa-check"></i><b>9.3.3</b> How To Scale</a></li>
<li class="chapter" data-level="9.3.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#order-of-processing"><i class="fa fa-check"></i><b>9.3.4</b> Order of Processing</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#low-variance-variables"><i class="fa fa-check"></i><b>9.4</b> Low Variance Variables</a></li>
<li class="chapter" data-level="9.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#order-of-pre-processing"><i class="fa fa-check"></i><b>9.5</b> Order of Pre-Processing</a></li>
<li class="chapter" data-level="9.6" data-path="data-pre-processing.html"><a href="data-pre-processing.html#identifying-redundant-features"><i class="fa fa-check"></i><b>9.6</b> Identifying Redundant Features</a><ul>
<li class="chapter" data-level="9.6.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#highly-correlated-variables"><i class="fa fa-check"></i><b>9.6.1</b> Highly Correlated Variables</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="data-pre-processing.html"><a href="data-pre-processing.html#ranking-features"><i class="fa fa-check"></i><b>9.7</b> Ranking Features</a></li>
<li class="chapter" data-level="9.8" data-path="data-pre-processing.html"><a href="data-pre-processing.html#feature-selection-1"><i class="fa fa-check"></i><b>9.8</b> Feature Selection</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="classification-problems.html"><a href="classification-problems.html"><i class="fa fa-check"></i><b>10</b> Classification Problems</a><ul>
<li class="chapter" data-level="10.1" data-path="classification-problems.html"><a href="classification-problems.html#hypothesis-testing"><i class="fa fa-check"></i><b>10.1</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="10.1.1" data-path="classification-problems.html"><a href="classification-problems.html#type-i-and-ii-errors"><i class="fa fa-check"></i><b>10.1.1</b> Type I and II Errors</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="classification-problems.html"><a href="classification-problems.html#performance-measures"><i class="fa fa-check"></i><b>10.2</b> Performance Measures</a></li>
<li class="chapter" data-level="10.3" data-path="classification-problems.html"><a href="classification-problems.html#table-of-outcomes"><i class="fa fa-check"></i><b>10.3</b> Table of Outcomes</a><ul>
<li class="chapter" data-level="10.3.1" data-path="classification-problems.html"><a href="classification-problems.html#computing-performance-metrics"><i class="fa fa-check"></i><b>10.3.1</b> Computing Performance Metrics</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="classification-problems.html"><a href="classification-problems.html#picking-the-right-metric"><i class="fa fa-check"></i><b>10.4</b> Picking the Right Metric</a><ul>
<li class="chapter" data-level="10.4.1" data-path="classification-problems.html"><a href="classification-problems.html#working-with-prediction-probabilities"><i class="fa fa-check"></i><b>10.4.1</b> Working With Prediction Probabilities</a></li>
<li class="chapter" data-level="10.4.2" data-path="classification-problems.html"><a href="classification-problems.html#creating-a-roc-curve"><i class="fa fa-check"></i><b>10.4.2</b> Creating a ROC Curve</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="classification-example.html"><a href="classification-example.html"><i class="fa fa-check"></i><b>11</b> Classification Example</a><ul>
<li class="chapter" data-level="11.1" data-path="classification-example.html"><a href="classification-example.html#boxplots-and-densities"><i class="fa fa-check"></i><b>11.1</b> Boxplots And Densities</a></li>
<li class="chapter" data-level="11.2" data-path="classification-example.html"><a href="classification-example.html#generalized-linear-models"><i class="fa fa-check"></i><b>11.2</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="11.3" data-path="classification-example.html"><a href="classification-example.html#random-forests-1"><i class="fa fa-check"></i><b>11.3</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html"><i class="fa fa-check"></i><b>12</b> Using External ML Frameworks</a><ul>
<li class="chapter" data-level="12.1" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-h2o"><i class="fa fa-check"></i><b>12.1</b> Using h2o</a></li>
<li class="chapter" data-level="12.2" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#create-some-h20-models"><i class="fa fa-check"></i><b>12.2</b> Create Some h20 Models</a></li>
<li class="chapter" data-level="12.3" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#saving-a-model"><i class="fa fa-check"></i><b>12.3</b> Saving A Model</a></li>
<li class="chapter" data-level="12.4" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-the-h2o-auto-ml-feature"><i class="fa fa-check"></i><b>12.4</b> Using The h2o Auto ML Feature</a></li>
<li class="chapter" data-level="12.5" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#launching-a-job"><i class="fa fa-check"></i><b>12.5</b> Launching a Job</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Learning in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification-problems" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Classification Problems</h1>
<p>Next up we consider the issue of building a model to predict a binary (e.g. “yes” / “no” or “positive /”negative“) outcome although we might also predict more than one class. For the sake of explanation we’ll keep our attention to the”two class&quot; situation. As an example, the mtcars data frame has a variable called <strong>am</strong> which indicates whether a car has an automatic or manual transmission. This is indicated, respectively, by a 0 and 1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(mtcars)</code></pre></div>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</code></pre>
<p>We could build a classification model to predict whether a car had an automatic or manual transmission based on one or more variables from the data frame. A more general example might be predicting whether a patient has tested positive or negative for a condition. Unlike prediciting a continuous outcome, we would be classifying an outcome as one thing or another. Evaluating such a model involves more than just computing RMSE. Let’s explore some considerations that need to be made.</p>
<div id="hypothesis-testing" class="section level2">
<h2><span class="header-section-number">10.1</span> Hypothesis Testing</h2>
<p>Now, before we dig into the details our classifier, remember that most things in statistics and classification revolves around the idea of a hypothesis. In this case, the “null” hypothesis is that a patient does NOT have the disease whereas the alternative hypothesis is that they do. Well, for a statistician that’s a bit strong. Let’s just say that if there is enough evidence to reject the null hypothesis then we will.</p>
<div id="type-i-and-ii-errors" class="section level3">
<h3><span class="header-section-number">10.1.1</span> Type I and II Errors</h3>
<p>Anyway, the larger idea is that we might apply our test to someone and subsequently determine that they have a disease when in fact they don’t. This would be an example of a “false positive” also known as a “Type I Error”. It is also possible that we apply the test to someone and we say that the do not have the disease when they actually do. This is known as a “false negative” also known as a Type II Error&quot; wherein we fail to reject the null hypothesis for this person. A perfect test would have zero false positives and zero false negatives</p>
</div>
</div>
<div id="performance-measures" class="section level2">
<h2><span class="header-section-number">10.2</span> Performance Measures</h2>
<p>With Linear Regression we were predicting a continuous outcome with the goal of being able to minimize the RMSE (root mean square error). In classification problems we need a metric or “performance measure” that we can use to judge the effectivness of any model we create.</p>
<p>Let’s say that we are predicting whether someone has a disease or not. Pretend we have a classifier that we use against a blood sample to make this determination. The outcome is either a 1 which means that the patient is positive for the condition whereas an outcome of 0 represents a negative.</p>
</div>
<div id="table-of-outcomes" class="section level2">
<h2><span class="header-section-number">10.3</span> Table of Outcomes</h2>
<p>We’ll generate two vectors here with one being named “actual” that represents the “truth” or “reality” of the situation. This is our reference against which we will compared our predictions. The second vector, imaginatively named “predicted”, contains the predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Pretend that this vector represents the actual condition status for the patients</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)
actual &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="dv">20</span>,T),<span class="dt">levels=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>))

<span class="co"># Pretend that we generated the following predictions using a really cool, highly-sophisticated model</span>
<span class="kw">set.seed</span>(<span class="dv">321</span>)
predicted &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="dv">20</span>,T),<span class="dt">levels=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>))</code></pre></div>
<p>We can now compare the predicted against the actual to see how “good” our model is. This table provdes the basis from which we can compute a number of performance measures</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(myt &lt;-<span class="st"> </span><span class="kw">table</span>(predicted,actual))</code></pre></div>
<pre><code>##          actual
## predicted 1 0
##         1 4 4
##         0 7 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(myt)</code></pre></div>
<pre><code>## [1] 20</code></pre>
<p>So first of all we notice that there are N = 20 people in this study. It might be helpful to view this table using some terminology:</p>
<div class="figure">
<img src="pics/cm1.png" width="1200" />

</div>
<p>True Positives - With respect to the first row - we predicted that 4 people have the disease that actually do have it. You could then say that the number of TRUE POSITIVES (abbreviated as “TP”) is 4.</p>
<p>False Positives - We also predicted that 4 people have the condition when they in fact do not. We could then say that the number of FALSE POSITIVES, abbreviated as “FP”, is 7. This is also known as a “Type 1” error.</p>
<p>False Negatives - In the second row we predicted that 7 people do NOT have the disease/condition when they actually do. So you could say that the number of FALSE NEGATIVES (abbreviated as FN) is 7.</p>
<p>True Negatives - We also predicted that 5 people do not have the condition and they do not. So then the number of TRUE NEGATIVES (abbreviated as TN) is also 5.</p>
<div id="computing-performance-metrics" class="section level3">
<h3><span class="header-section-number">10.3.1</span> Computing Performance Metrics</h3>
<p>Now comes the fun part in that you might be concerned with specific metrics to assess the quality of your model in specific terms. Since our model, such as it is, seems to relate to the quality of a medical diagnostic we might be concerned with its accuracy, precision, and sensitivty. The first two terms in particular are frequently used synonymously when they are not the same thing. Remember that we have N = 20 patients. Below is a graphic from Wikipedia which presents many (if not all) of the metrics that can be computed against a confusion matrix.</p>
<div class="figure">
<img src="pics/cmwiki.png" width="1200" />

</div>
<p>We’ll focus on some specific metrics as they will assist our understanding of how to assess a model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">myt</code></pre></div>
<pre><code>##          actual
## predicted 1 0
##         1 4 4
##         0 7 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(myt)</code></pre></div>
<pre><code>## [1] 20</code></pre>
<div id="accuracy" class="section level4">
<h4><span class="header-section-number">10.3.1.1</span> Accuracy</h4>
<p>So let’s take the number of observed True Positives and True Negatives, add them together, and divide them by the total number of patients in the study group to arrive at what is known as the <strong>Accuracy</strong> of our model. Another way to think of the denominator is as the sum of all observed results, True and False.</p>
<p>Accuracy = (TP + TN) / (TP + TN + FP + FN) = 9/20 = 0.45</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(accuracy &lt;-<span class="st"> </span>(myt[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>myt[<span class="dv">2</span>,<span class="dv">2</span>]) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(myt))</code></pre></div>
<pre><code>## [1] 0.45</code></pre>
</div>
<div id="precision" class="section level4">
<h4><span class="header-section-number">10.3.1.2</span> Precision</h4>
<p>How precise is the model ? This is computed in a different fashion. We take the number of True Postives (TP) and divide that by the sum of True Positives (TP) and False Positives (FP). The denominator is the sum of row 1 in our table myt.</p>
<p>Precision = TP / (TP + FP) = 4 / (4 + 4) = 0.5</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(precision &lt;-<span class="st"> </span>myt[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">/</span>(myt[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">+</span>myt[<span class="dv">1</span>,<span class="dv">2</span>]))</code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<p>It is helpful to know that <strong>Precision</strong> is also known as the PPV “Positive Predictive Value” since it is concerened with the ratio of True Positives over the sum of all Positive related quantities including the False Positives. The larger the number of FP then the smaller the ratio which results in a lower precision.</p>
</div>
<div id="sensitivity" class="section level4">
<h4><span class="header-section-number">10.3.1.3</span> Sensitivity</h4>
<p>Sensitivity is related to Precision except the ratio we look at is the number of True Positives (TP) divided by the sum of True Positives and False Negatives (which are actually Positives). This tells us how frequently we find a positive case given that it is actually positive.</p>
<p>Sensitivity = TP / (TP + FN) = 5 / (5 + 4) = 0.5555</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(sensitivity &lt;-<span class="st"> </span>myt[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">/</span>(myt[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">+</span>myt[<span class="dv">2</span>,<span class="dv">1</span>]))</code></pre></div>
<pre><code>## [1] 0.3636364</code></pre>
<p>Sensitivity also has synonyms: recall, hit rate, or True Positive Rate (TPR). For example, the concept of True Positive Rate might be more intutitive for you to understand although scientific medical literature might reference Sensitivity.</p>
</div>
<div id="specificity" class="section level4">
<h4><span class="header-section-number">10.3.1.4</span> Specificity</h4>
<p>Specificity tells us how frequently we find a negative case given that it is actually negative. This is also known as the “True Negative Rate”</p>
<p>Specificity = TN / (TN + FP) = 5 / (5 + 4) = 0.5555</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(specificity &lt;-<span class="st"> </span>myt[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">/</span>(myt[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">+</span>myt[<span class="dv">1</span>,<span class="dv">2</span>]))</code></pre></div>
<pre><code>## [1] 0.5555556</code></pre>
</div>
<div id="false-positive-rate" class="section level4">
<h4><span class="header-section-number">10.3.1.5</span> False Positive Rate</h4>
<p>We compute the FPR as follows:</p>
<p>False Positive Rate = FP / FP + TN = 4 / 4 + 5</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(fpr &lt;-<span class="st"> </span>myt[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">/</span><span class="st"> </span>(myt[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>myt[<span class="dv">2</span>,<span class="dv">2</span>]))</code></pre></div>
<pre><code>## [1] 0.4444444</code></pre>
</div>
</div>
</div>
<div id="picking-the-right-metric" class="section level2">
<h2><span class="header-section-number">10.4</span> Picking the Right Metric</h2>
<p>There are more ratios we could compute some of which might be more relavant to our classification issue. In reality, picking the “right” metric is a function of your domain of study. Frequently, the sensitivity and specicity are used in medical testing scenarions as is the false positive rate. But you should search the literature in your area of interest to determine what is commonly used. We could say much more about these metrics but we’ll keep it simple for now.</p>
<p>Where are we ? We compared some predictions against reality and computed some ratios. The problem with this is that we don’t yet know from where the predictions came ? Well, we imagined that the predicted values came from some classification model we created though we didn’t specify one. Let’s take a real example here to illustrate some important points.</p>
<p>Let’s use the <strong>PimaIndiansDiabetes</strong> data frame from the <strong>mlbench</strong> package to predict whether a person has diabetes or not. This is just a basic example here, we aren’t trying to create a sophisticated model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;PimaIndiansDiabetes&quot;</span>)
pm &lt;-<span class="st"> </span>PimaIndiansDiabetes

<span class="co"># Create a logistic regression model</span>
glm_model &lt;-<span class="st"> </span><span class="kw">glm</span>(diabetes <span class="op">~</span><span class="st"> </span>.,<span class="dt">data=</span>pm,<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)</code></pre></div>
<p>Now that we have a model, let’s do some predictions. What we get back are probabilities (values between 0 and 1). We now have to figure out an appropriate threshold value that, if exceeded, will result in a classification of “positive” for diabetes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm_probs &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_model,pm,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
<span class="kw">round</span>(glm_probs,<span class="dv">4</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>]</code></pre></div>
<pre><code>##      1      2      3      4      5      6      7      8      9     10 
## 0.7217 0.0486 0.7967 0.0416 0.9022 0.1466 0.0666 0.6446 0.7094 0.0363 
##     11     12     13     14     15     16     17     18     19     20 
## 0.2196 0.8978 0.7844 0.6286 0.6276 0.4009 0.3712 0.1966 0.3575 0.2342</code></pre>
<p>Let’s create a boxplot of these probabilities.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">boxplot</span>(glm_probs)
<span class="kw">grid</span>()
<span class="kw">hist</span>(glm_probs)</code></pre></div>
<p><img src="biosml_files/figure-html/unnamed-chunk-106-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</code></pre></div>
<div id="working-with-prediction-probabilities" class="section level3">
<h3><span class="header-section-number">10.4.1</span> Working With Prediction Probabilities</h3>
<p>So now we need to write some code to decide how to best use these probabilities to make the predictions. We’ll start with 0.5. (That’s what most people do anyway). If the predicted probability corresponding to that observation is &gt;= 0.5 then we’ll say that the person has diabetes. If not, then they will be classified as negative.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t &lt;-<span class="st"> </span><span class="fl">0.5</span>
diabetes &lt;-<span class="st"> </span><span class="kw">ifelse</span>(glm_probs <span class="op">&gt;=</span><span class="st"> </span>t,<span class="dv">0</span>,<span class="dv">1</span>)</code></pre></div>
<p>Next, let’s make a table which compares these predictions against the actual values. It turns out that our classifier doesn’t seem to be doing a good job here. There are lots of False Negatives and Positives here.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(myt &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="dt">predicted=</span>diabetes,<span class="dt">true=</span>pm<span class="op">$</span>diabetes))</code></pre></div>
<pre><code>##          true
## predicted neg pos
##         0  55 156
##         1 445 112</code></pre>
<p>So we could then compute the metrics corresponding to this particular confusion matrix. We could compute, for example, the True Positive Rate and False Positive Rate from this data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">get_tprfpr &lt;-<span class="st"> </span><span class="cf">function</span>(pred,true) {
  myt &lt;-<span class="st"> </span><span class="kw">table</span>(pred,true)
  tpr &lt;-<span class="st"> </span>myt[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">/</span>(myt[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">+</span>myt[<span class="dv">2</span>,<span class="dv">1</span>])
  fpr &lt;-<span class="st"> </span>myt[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">/</span><span class="st"> </span>(myt[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>myt[<span class="dv">2</span>,<span class="dv">2</span>])
  <span class="kw">return</span>(<span class="kw">c</span>(<span class="dt">tpr=</span>tpr,<span class="dt">fpr=</span>fpr))
}

<span class="kw">get_tprfpr</span>(diabetes,pm<span class="op">$</span>diabetes)</code></pre></div>
<pre><code>##       tpr       fpr 
## 0.1100000 0.5820896</code></pre>
</div>
<div id="creating-a-roc-curve" class="section level3">
<h3><span class="header-section-number">10.4.2</span> Creating a ROC Curve</h3>
<p>Let’s look at the metrics associated with other threshold values. Even better let’s just adjust our above function to do this for all values between 0 and 1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">get_tprfpr &lt;-<span class="st"> </span><span class="cf">function</span>(thresh,<span class="dt">probs=</span>glm_probs) {
  diabetes &lt;-<span class="st"> </span><span class="kw">ifelse</span>(probs <span class="op">&gt;=</span><span class="st"> </span>thresh,<span class="dv">1</span>,<span class="dv">0</span>)
  myt &lt;-<span class="st"> </span><span class="kw">table</span>(diabetes,pm<span class="op">$</span>diabetes)
  tpr &lt;-<span class="st"> </span>myt[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">/</span>(myt[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">+</span>myt[<span class="dv">2</span>,<span class="dv">1</span>])
  fpr &lt;-<span class="st"> </span>myt[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">/</span><span class="st"> </span>(myt[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>myt[<span class="dv">2</span>,<span class="dv">2</span>])
  <span class="kw">return</span>(<span class="kw">c</span>(<span class="dt">tpr=</span>tpr,<span class="dt">fpr=</span>fpr))
}</code></pre></div>
<p>So - This process has resulted in the creation of a ROC Curve that shows us TPR vs FPR across a large number of possible threshold values. For each selected threshold, we compute a confusion matrix from which we compute the associated tpr and fpr. When we are done, we plot tpr vs fpr. The idea with a ROC curve is to pick the threshold such that the area under the curve is maximized. While we have produced this ROC curve by hand, R provides packages to do this for us.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">metrics &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(<span class="kw">seq</span>(<span class="fl">0.05</span>,.<span class="dv">95</span>,.<span class="dv">05</span>),<span class="cf">function</span>(x) <span class="kw">get_tprfpr</span>(x))) 
<span class="kw">plot</span>(tpr<span class="op">~</span>fpr,metrics,
     <span class="dt">main=</span><span class="st">&quot;Steve&#39;s ROC Curve&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;False Positve Rate (1-Specificity)&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;True Positive Rate&quot;</span>,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>)
<span class="kw">grid</span>()

<span class="co"># Put the associated threshold values on the plot to help you identify</span>
<span class="co"># the right value to maximize the AUC (Area Under Curve)</span>

<span class="kw">text</span>(metrics[,<span class="dv">2</span>],metrics[,<span class="dv">1</span>],<span class="dt">labels=</span><span class="kw">seq</span>(<span class="fl">0.05</span>,.<span class="dv">95</span>,.<span class="dv">05</span>),<span class="dt">cex=</span><span class="fl">0.9</span>)</code></pre></div>
<p><img src="biosml_files/figure-html/unnamed-chunk-111-1.png" width="672" /></p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-pre-processing.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classification-example.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
