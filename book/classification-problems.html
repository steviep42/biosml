<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Classification Problems | Predictive Learning in R</title>
  <meta name="description" content="Chapter 6 Classification Problems | Predictive Learning in R" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Classification Problems | Predictive Learning in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Classification Problems | Predictive Learning in R" />
  
  
  

<meta name="author" content="Steve Pittard - wsp@emory.edu" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="caret-package.html"/>
<link rel="next" href="classification-example.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#machine-learning"><i class="fa fa-check"></i><b>1.1</b> Machine Learning</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#predictive-modeling"><i class="fa fa-check"></i><b>1.2</b> Predictive Modeling</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#in-sample-vs-out-of-sample-error"><i class="fa fa-check"></i><b>1.3</b> In-Sample vs Out-Of-Sample Error</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#performance-metrics"><i class="fa fa-check"></i><b>1.4</b> Performance Metrics</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#black-box"><i class="fa fa-check"></i><b>1.5</b> Black Box</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html"><i class="fa fa-check"></i><b>2</b> Predictive / Supervised Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#explanation-vs-prediction"><i class="fa fa-check"></i><b>2.1</b> Explanation vs Prediction</a><ul>
<li class="chapter" data-level="2.1.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#titanic-data"><i class="fa fa-check"></i><b>2.1.1</b> Titanic Data</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#bias-vs-variance"><i class="fa fa-check"></i><b>2.2</b> Bias vs Variance</a><ul>
<li class="chapter" data-level="2.2.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#bias"><i class="fa fa-check"></i><b>2.2.1</b> Bias</a></li>
<li class="chapter" data-level="2.2.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#variance"><i class="fa fa-check"></i><b>2.2.2</b> Variance</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#overfitting-and-underfitting"><i class="fa fa-check"></i><b>2.3</b> Overfitting and Underfitting</a></li>
<li class="chapter" data-level="2.4" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#some-important-terminology"><i class="fa fa-check"></i><b>2.4</b> Some Important Terminology</a></li>
<li class="chapter" data-level="2.5" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#levels-of-measurement"><i class="fa fa-check"></i><b>2.5</b> Levels of Measurement</a><ul>
<li class="chapter" data-level="2.5.1" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#nominal"><i class="fa fa-check"></i><b>2.5.1</b> Nominal</a></li>
<li class="chapter" data-level="2.5.2" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#ordinal"><i class="fa fa-check"></i><b>2.5.2</b> Ordinal</a></li>
<li class="chapter" data-level="2.5.3" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#interval"><i class="fa fa-check"></i><b>2.5.3</b> Interval</a></li>
<li class="chapter" data-level="2.5.4" data-path="predictive-supervised-learning.html"><a href="predictive-supervised-learning.html#ratio"><i class="fa fa-check"></i><b>2.5.4</b> Ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-motivating-example.html"><a href="a-motivating-example.html"><i class="fa fa-check"></i><b>3</b> A Motivating Example</a><ul>
<li class="chapter" data-level="3.1" data-path="a-motivating-example.html"><a href="a-motivating-example.html#a-more-detailed-workflow"><i class="fa fa-check"></i><b>3.1</b> A More Detailed Workflow</a></li>
<li class="chapter" data-level="3.2" data-path="a-motivating-example.html"><a href="a-motivating-example.html#visualizations"><i class="fa fa-check"></i><b>3.2</b> Visualizations</a><ul>
<li class="chapter" data-level="3.2.1" data-path="a-motivating-example.html"><a href="a-motivating-example.html#scatterplots"><i class="fa fa-check"></i><b>3.2.1</b> Scatterplots</a></li>
<li class="chapter" data-level="3.2.2" data-path="a-motivating-example.html"><a href="a-motivating-example.html#boxplots"><i class="fa fa-check"></i><b>3.2.2</b> Boxplots</a></li>
<li class="chapter" data-level="3.2.3" data-path="a-motivating-example.html"><a href="a-motivating-example.html#histograms"><i class="fa fa-check"></i><b>3.2.3</b> Histograms</a></li>
<li class="chapter" data-level="3.2.4" data-path="a-motivating-example.html"><a href="a-motivating-example.html#tables"><i class="fa fa-check"></i><b>3.2.4</b> Tables</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="a-motivating-example.html"><a href="a-motivating-example.html#correlations"><i class="fa fa-check"></i><b>3.3</b> Correlations</a></li>
<li class="chapter" data-level="3.4" data-path="a-motivating-example.html"><a href="a-motivating-example.html#building-a-model---in-sample-error"><i class="fa fa-check"></i><b>3.4</b> Building A Model - In Sample Error</a></li>
<li class="chapter" data-level="3.5" data-path="a-motivating-example.html"><a href="a-motivating-example.html#out-of-sample-data"><i class="fa fa-check"></i><b>3.5</b> Out Of Sample Data</a></li>
<li class="chapter" data-level="3.6" data-path="a-motivating-example.html"><a href="a-motivating-example.html#some-additional-considerations"><i class="fa fa-check"></i><b>3.6</b> Some Additional Considerations</a></li>
<li class="chapter" data-level="3.7" data-path="a-motivating-example.html"><a href="a-motivating-example.html#other-methods"><i class="fa fa-check"></i><b>3.7</b> Other Methods ?</a></li>
<li class="chapter" data-level="3.8" data-path="a-motivating-example.html"><a href="a-motivating-example.html#summary"><i class="fa fa-check"></i><b>3.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="training-test-data.html"><a href="training-test-data.html"><i class="fa fa-check"></i><b>4</b> Training / Test Data</a><ul>
<li class="chapter" data-level="4.1" data-path="training-test-data.html"><a href="training-test-data.html#cross-fold-validation"><i class="fa fa-check"></i><b>4.1</b> Cross Fold Validation</a></li>
<li class="chapter" data-level="4.2" data-path="training-test-data.html"><a href="training-test-data.html#create-a-function-to-automate-things"><i class="fa fa-check"></i><b>4.2</b> Create A Function To Automate Things</a></li>
<li class="chapter" data-level="4.3" data-path="training-test-data.html"><a href="training-test-data.html#repeated-cross-validation"><i class="fa fa-check"></i><b>4.3</b> Repeated Cross Validation</a></li>
<li class="chapter" data-level="4.4" data-path="training-test-data.html"><a href="training-test-data.html#bootstrap"><i class="fa fa-check"></i><b>4.4</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="caret-package.html"><a href="caret-package.html"><i class="fa fa-check"></i><b>5</b> Caret Package</a><ul>
<li class="chapter" data-level="5.1" data-path="caret-package.html"><a href="caret-package.html#putting-caret-to-work"><i class="fa fa-check"></i><b>5.1</b> Putting caret To Work</a></li>
<li class="chapter" data-level="5.2" data-path="caret-package.html"><a href="caret-package.html#back-to-the-beginning"><i class="fa fa-check"></i><b>5.2</b> Back To The Beginning</a></li>
<li class="chapter" data-level="5.3" data-path="caret-package.html"><a href="caret-package.html#splitting"><i class="fa fa-check"></i><b>5.3</b> Splitting</a></li>
<li class="chapter" data-level="5.4" data-path="caret-package.html"><a href="caret-package.html#calling-the-train-function"><i class="fa fa-check"></i><b>5.4</b> Calling The train() Function</a></li>
<li class="chapter" data-level="5.5" data-path="caret-package.html"><a href="caret-package.html#reproducible-results"><i class="fa fa-check"></i><b>5.5</b> Reproducible Results</a></li>
<li class="chapter" data-level="5.6" data-path="caret-package.html"><a href="caret-package.html#one-size-fits-all"><i class="fa fa-check"></i><b>5.6</b> One Size Fits All</a></li>
<li class="chapter" data-level="5.7" data-path="caret-package.html"><a href="caret-package.html#alternative-calling-sequence"><i class="fa fa-check"></i><b>5.7</b> Alternative Calling Sequence</a></li>
<li class="chapter" data-level="5.8" data-path="caret-package.html"><a href="caret-package.html#hyperparameters"><i class="fa fa-check"></i><b>5.8</b> Hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification-problems.html"><a href="classification-problems.html"><i class="fa fa-check"></i><b>6</b> Classification Problems</a><ul>
<li class="chapter" data-level="6.1" data-path="classification-problems.html"><a href="classification-problems.html#performance-measures"><i class="fa fa-check"></i><b>6.1</b> Performance Measures</a></li>
<li class="chapter" data-level="6.2" data-path="classification-problems.html"><a href="classification-problems.html#important-terminology"><i class="fa fa-check"></i><b>6.2</b> Important Terminology</a></li>
<li class="chapter" data-level="6.3" data-path="classification-problems.html"><a href="classification-problems.html#a-basic-model"><i class="fa fa-check"></i><b>6.3</b> A Basic Model</a></li>
<li class="chapter" data-level="6.4" data-path="classification-problems.html"><a href="classification-problems.html#selecting-the-correct-threshold-alpha"><i class="fa fa-check"></i><b>6.4</b> Selecting The Correct Threshold / Alpha</a><ul>
<li class="chapter" data-level="6.4.1" data-path="classification-problems.html"><a href="classification-problems.html#moving-the-threshold"><i class="fa fa-check"></i><b>6.4.1</b> Moving The Threshold</a></li>
<li class="chapter" data-level="6.4.2" data-path="classification-problems.html"><a href="classification-problems.html#distribution-of-predicted-probabilities"><i class="fa fa-check"></i><b>6.4.2</b> Distribution of Predicted Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="classification-problems.html"><a href="classification-problems.html#hypothesis-testing"><i class="fa fa-check"></i><b>6.5</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="6.6" data-path="classification-problems.html"><a href="classification-problems.html#confusion-matrix"><i class="fa fa-check"></i><b>6.6</b> Confusion Matrix</a><ul>
<li class="chapter" data-level="6.6.1" data-path="classification-problems.html"><a href="classification-problems.html#computing-performance-metrics"><i class="fa fa-check"></i><b>6.6.1</b> Computing Performance Metrics</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="classification-problems.html"><a href="classification-problems.html#picking-the-right-metric"><i class="fa fa-check"></i><b>6.7</b> Picking the Right Metric</a></li>
<li class="chapter" data-level="6.8" data-path="classification-problems.html"><a href="classification-problems.html#wait.-where-are-we"><i class="fa fa-check"></i><b>6.8</b> Wait. Where Are We ?</a></li>
<li class="chapter" data-level="6.9" data-path="classification-problems.html"><a href="classification-problems.html#other-ways-to-compute-the-roc-curve"><i class="fa fa-check"></i><b>6.9</b> Other Ways To Compute The ROC Curve</a></li>
<li class="chapter" data-level="6.10" data-path="classification-problems.html"><a href="classification-problems.html#roc-curve-summary"><i class="fa fa-check"></i><b>6.10</b> ROC Curve Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification-example.html"><a href="classification-example.html"><i class="fa fa-check"></i><b>7</b> Classification Example</a><ul>
<li class="chapter" data-level="7.1" data-path="classification-example.html"><a href="classification-example.html#exploratory-plots"><i class="fa fa-check"></i><b>7.1</b> Exploratory Plots</a></li>
<li class="chapter" data-level="7.2" data-path="classification-example.html"><a href="classification-example.html#generalized-linear-models"><i class="fa fa-check"></i><b>7.2</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="7.3" data-path="classification-example.html"><a href="classification-example.html#random-forests"><i class="fa fa-check"></i><b>7.3</b> Random Forests</a></li>
<li class="chapter" data-level="7.4" data-path="classification-example.html"><a href="classification-example.html#feature-importance"><i class="fa fa-check"></i><b>7.4</b> Feature Importance</a></li>
<li class="chapter" data-level="7.5" data-path="classification-example.html"><a href="classification-example.html#target-variable-format"><i class="fa fa-check"></i><b>7.5</b> Target Variable Format</a></li>
<li class="chapter" data-level="7.6" data-path="classification-example.html"><a href="classification-example.html#addressing-class-imbalance"><i class="fa fa-check"></i><b>7.6</b> Addressing Class Imbalance</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>8</b> Decision Trees</a><ul>
<li class="chapter" data-level="8.1" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>8.1</b> Advantages</a></li>
<li class="chapter" data-level="8.2" data-path="decision-trees.html"><a href="decision-trees.html#a-classification-example"><i class="fa fa-check"></i><b>8.2</b> A Classification Example</a></li>
<li class="chapter" data-level="8.3" data-path="decision-trees.html"><a href="decision-trees.html#digging-deeper"><i class="fa fa-check"></i><b>8.3</b> Digging Deeper</a><ul>
<li class="chapter" data-level="8.3.1" data-path="decision-trees.html"><a href="decision-trees.html#evaluating-performance"><i class="fa fa-check"></i><b>8.3.1</b> Evaluating performance</a></li>
<li class="chapter" data-level="8.3.2" data-path="decision-trees.html"><a href="decision-trees.html#tree-splitting"><i class="fa fa-check"></i><b>8.3.2</b> Tree Splitting</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="decision-trees.html"><a href="decision-trees.html#gini-index"><i class="fa fa-check"></i><b>8.4</b> Gini Index</a></li>
<li class="chapter" data-level="8.5" data-path="decision-trees.html"><a href="decision-trees.html#regression-trees"><i class="fa fa-check"></i><b>8.5</b> Regression Trees</a><ul>
<li class="chapter" data-level="8.5.1" data-path="decision-trees.html"><a href="decision-trees.html#performance-measure"><i class="fa fa-check"></i><b>8.5.1</b> Performance Measure</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="decision-trees.html"><a href="decision-trees.html#parameters-vs-hyperparameters"><i class="fa fa-check"></i><b>8.6</b> Parameters vs Hyperparameters</a></li>
<li class="chapter" data-level="8.7" data-path="decision-trees.html"><a href="decision-trees.html#grid-searching"><i class="fa fa-check"></i><b>8.7</b> Grid Searching</a></li>
<li class="chapter" data-level="8.8" data-path="decision-trees.html"><a href="decision-trees.html#bagged-trees"><i class="fa fa-check"></i><b>8.8</b> Bagged Trees</a></li>
<li class="chapter" data-level="8.9" data-path="decision-trees.html"><a href="decision-trees.html#random-forests-1"><i class="fa fa-check"></i><b>8.9</b> Random Forests</a></li>
<li class="chapter" data-level="8.10" data-path="decision-trees.html"><a href="decision-trees.html#boosted-trees"><i class="fa fa-check"></i><b>8.10</b> Boosted Trees</a></li>
<li class="chapter" data-level="8.11" data-path="decision-trees.html"><a href="decision-trees.html#using-caret"><i class="fa fa-check"></i><b>8.11</b> Using caret</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="using-different-methods.html"><a href="using-different-methods.html"><i class="fa fa-check"></i><b>9</b> Using Different Methods</a><ul>
<li class="chapter" data-level="9.1" data-path="using-different-methods.html"><a href="using-different-methods.html#parameters-vs-hyperparameters-1"><i class="fa fa-check"></i><b>9.1</b> Parameters vs Hyperparameters</a></li>
<li class="chapter" data-level="9.2" data-path="using-different-methods.html"><a href="using-different-methods.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>9.2</b> Hyperparameter Tuning</a><ul>
<li class="chapter" data-level="9.2.1" data-path="using-different-methods.html"><a href="using-different-methods.html#multiple-hyperparameters"><i class="fa fa-check"></i><b>9.2.1</b> Multiple Hyperparameters ?</a></li>
<li class="chapter" data-level="9.2.2" data-path="using-different-methods.html"><a href="using-different-methods.html#custom-tuning-grid"><i class="fa fa-check"></i><b>9.2.2</b> Custom Tuning Grid</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="using-different-methods.html"><a href="using-different-methods.html#using-validation-data-sets"><i class="fa fa-check"></i><b>9.3</b> Using Validation Data Sets</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html"><i class="fa fa-check"></i><b>10</b> Selecting The Best Model</a><ul>
<li class="chapter" data-level="10.1" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#an-example"><i class="fa fa-check"></i><b>10.1</b> An Example</a></li>
<li class="chapter" data-level="10.2" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#more-comparisons"><i class="fa fa-check"></i><b>10.2</b> More Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#using-the-resamples-function"><i class="fa fa-check"></i><b>10.3</b> Using the resamples() function</a></li>
<li class="chapter" data-level="10.4" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#model-performance"><i class="fa fa-check"></i><b>10.4</b> Model Performance</a></li>
<li class="chapter" data-level="10.5" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#feature-evaluation"><i class="fa fa-check"></i><b>10.5</b> Feature Evaluation</a><ul>
<li class="chapter" data-level="10.5.1" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#identifying-redundant-features"><i class="fa fa-check"></i><b>10.5.1</b> Identifying Redundant Features</a></li>
<li class="chapter" data-level="10.5.2" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#highly-correlated-variables"><i class="fa fa-check"></i><b>10.5.2</b> Highly Correlated Variables</a></li>
<li class="chapter" data-level="10.5.3" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#ranking-features"><i class="fa fa-check"></i><b>10.5.3</b> Ranking Features</a></li>
<li class="chapter" data-level="10.5.4" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#feature-selection"><i class="fa fa-check"></i><b>10.5.4</b> Feature Selection</a></li>
<li class="chapter" data-level="10.5.5" data-path="selecting-the-best-model.html"><a href="selecting-the-best-model.html#recursive-feature-elimination"><i class="fa fa-check"></i><b>10.5.5</b> Recursive Feature Elimination</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>11</b> Data Pre Processing</a><ul>
<li class="chapter" data-level="11.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#types-of-pre-processing"><i class="fa fa-check"></i><b>11.1</b> Types of Pre Processing</a></li>
<li class="chapter" data-level="11.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#missing-values"><i class="fa fa-check"></i><b>11.2</b> Missing Values</a><ul>
<li class="chapter" data-level="11.2.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#finding-rows-with-missing-data"><i class="fa fa-check"></i><b>11.2.1</b> Finding Rows with Missing Data</a></li>
<li class="chapter" data-level="11.2.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#finding-columns-with-missing-data"><i class="fa fa-check"></i><b>11.2.2</b> Finding Columns With Missing Data</a></li>
<li class="chapter" data-level="11.2.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#use-the-median-approach"><i class="fa fa-check"></i><b>11.2.3</b> Use the Median Approach</a></li>
<li class="chapter" data-level="11.2.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#package-based-approach"><i class="fa fa-check"></i><b>11.2.4</b> Package-based Approach</a></li>
<li class="chapter" data-level="11.2.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#using-caret-1"><i class="fa fa-check"></i><b>11.2.5</b> Using caret</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#scaling"><i class="fa fa-check"></i><b>11.3</b> Scaling</a><ul>
<li class="chapter" data-level="11.3.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#methods-that-benefit-from-scaling"><i class="fa fa-check"></i><b>11.3.1</b> Methods That Benefit From Scaling</a></li>
<li class="chapter" data-level="11.3.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#methods-that-do-not-require-scaling"><i class="fa fa-check"></i><b>11.3.2</b> Methods That Do Not Require Scaling</a></li>
<li class="chapter" data-level="11.3.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#how-to-scale"><i class="fa fa-check"></i><b>11.3.3</b> How To Scale</a></li>
<li class="chapter" data-level="11.3.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#order-of-processing"><i class="fa fa-check"></i><b>11.3.4</b> Order of Processing</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#low-variance-variables"><i class="fa fa-check"></i><b>11.4</b> Low Variance Variables</a></li>
<li class="chapter" data-level="11.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#pca---principal-components-analysis"><i class="fa fa-check"></i><b>11.5</b> PCA - Principal Components Analysis</a><ul>
<li class="chapter" data-level="11.5.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#identify-the-factors"><i class="fa fa-check"></i><b>11.5.1</b> Identify The Factors</a></li>
<li class="chapter" data-level="11.5.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#check-for-high-correlations"><i class="fa fa-check"></i><b>11.5.2</b> Check For High Correlations</a></li>
<li class="chapter" data-level="11.5.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#so-why-use-pca"><i class="fa fa-check"></i><b>11.5.3</b> So Why Use PCA ?</a></li>
<li class="chapter" data-level="11.5.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#check-the-biplot"><i class="fa fa-check"></i><b>11.5.4</b> Check The BiPlot</a></li>
<li class="chapter" data-level="11.5.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#check-the-screeplot"><i class="fa fa-check"></i><b>11.5.5</b> Check The ScreePlot</a></li>
<li class="chapter" data-level="11.5.6" data-path="data-pre-processing.html"><a href="data-pre-processing.html#use-the-transformed-data"><i class="fa fa-check"></i><b>11.5.6</b> Use The Transformed Data</a></li>
<li class="chapter" data-level="11.5.7" data-path="data-pre-processing.html"><a href="data-pre-processing.html#pls"><i class="fa fa-check"></i><b>11.5.7</b> PLS</a></li>
<li class="chapter" data-level="11.5.8" data-path="data-pre-processing.html"><a href="data-pre-processing.html#summary-1"><i class="fa fa-check"></i><b>11.5.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="data-pre-processing.html"><a href="data-pre-processing.html#order-of-pre-processing"><i class="fa fa-check"></i><b>11.6</b> Order of Pre-Processing</a></li>
<li class="chapter" data-level="11.7" data-path="data-pre-processing.html"><a href="data-pre-processing.html#handling-categories"><i class="fa fa-check"></i><b>11.7</b> Handling Categories</a><ul>
<li class="chapter" data-level="11.7.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#examples"><i class="fa fa-check"></i><b>11.7.1</b> Examples</a></li>
<li class="chapter" data-level="11.7.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#admissions-data"><i class="fa fa-check"></i><b>11.7.2</b> Admissions Data</a></li>
<li class="chapter" data-level="11.7.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#is-rank-a-category"><i class="fa fa-check"></i><b>11.7.3</b> Is Rank A Category ?</a></li>
<li class="chapter" data-level="11.7.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#relationship-to-one-hot-encoding"><i class="fa fa-check"></i><b>11.7.4</b> Relationship To One Hot Encoding</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="data-pre-processing.html"><a href="data-pre-processing.html#binning"><i class="fa fa-check"></i><b>11.8</b> Binning</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html"><i class="fa fa-check"></i><b>12</b> Using External ML Frameworks</a><ul>
<li class="chapter" data-level="12.1" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-h2o"><i class="fa fa-check"></i><b>12.1</b> Using h2o</a></li>
<li class="chapter" data-level="12.2" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#create-some-h20-models"><i class="fa fa-check"></i><b>12.2</b> Create Some h20 Models</a></li>
<li class="chapter" data-level="12.3" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#saving-a-model"><i class="fa fa-check"></i><b>12.3</b> Saving A Model</a></li>
<li class="chapter" data-level="12.4" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#using-the-h2o-auto-ml-feature"><i class="fa fa-check"></i><b>12.4</b> Using The h2o Auto ML Feature</a></li>
<li class="chapter" data-level="12.5" data-path="using-external-ml-frameworks.html"><a href="using-external-ml-frameworks.html#launching-a-job"><i class="fa fa-check"></i><b>12.5</b> Launching a Job</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Learning in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification-problems" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Classification Problems</h1>
<p>Next up we consider the issue of building a model to predict a binary (e.g. “yes” / “no” or “positive /”negative“) outcome although we might also predict more than one class. For the sake of explanation we’ll keep our attention to the”two class&quot; situation.</p>
<div id="performance-measures" class="section level2">
<h2><span class="header-section-number">6.1</span> Performance Measures</h2>
<p>With Linear Regression we were predicting a continuous outcome with the goal of being able to minimize the RMSE (root mean square error). In classification problems we need a metric or “performance measure” that we can use to judge the effectiveness of any model we create. Typically in classification we would be predicting some binary outcome such as whether someone has a disease or not. In this case it would not make sense to use something like RMSE. Other measures such as Accuracy, Precision, or Sensitivity are more appropriate.</p>
<p>An example might help - we’ll be spending some time with the <em>PimaIndiansDiabetes</em> dataframe that is part of the <strong>mlbench</strong> package. This is part of the <strong>mlbench</strong> package or you can read it in straight from the internet.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb191-1" data-line-number="1"><span class="co"># Option install</span></a>
<a class="sourceLine" id="cb191-2" data-line-number="2"><span class="kw">install.packages</span>(<span class="st">&quot;mlbench&quot;</span>)</a></code></pre></div>
<p>Once you have it installed then load it into the work space as follows:</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;PimaIndiansDiabetes&quot;</span>)</a>
<a class="sourceLine" id="cb192-2" data-line-number="2"></a>
<a class="sourceLine" id="cb192-3" data-line-number="3"><span class="co"># Get a shorter handle. I hate typing. </span></a>
<a class="sourceLine" id="cb192-4" data-line-number="4">pm &lt;-<span class="st"> </span>PimaIndiansDiabetes</a></code></pre></div>
<p>Or just read it in.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb193-1" data-line-number="1">url &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/steviep42/bios534_spring_2020/master/data/pima.csv&quot;</span></a>
<a class="sourceLine" id="cb193-2" data-line-number="2">pm &lt;-<span class="st"> </span><span class="kw">read.csv</span>(url)</a></code></pre></div>
<p>The description of the data set is as follows:</p>
<p><img src="pics/pima_desc.png" width="475" /></p>
<p>So we now have some data on which we can build a model. Specifically, there is a variable in the data called “diabetes” which indicates the disease / diabetes status (“pos” or “neg”) of the person. It would be good to come up with a model that we could use with incoming data to determine if someone has diabetes.</p>
</div>
<div id="important-terminology" class="section level2">
<h2><span class="header-section-number">6.2</span> Important Terminology</h2>
<p>In predictive modeling there are some common terms to consider:</p>
<p><img src="pics/features2.png" width="475" /></p>
</div>
<div id="a-basic-model" class="section level2">
<h2><span class="header-section-number">6.3</span> A Basic Model</h2>
<p>Since we are attempting to predict a binary outcome here (“pos” or “neg”) we’ll need to use something other than linear regression which is used to predict numeric outcomes. We’ll go with Logistic Regression as it is a tried and true method for doing this type of thing.</p>
<p>Let’s use the native <strong>glm</strong> function to do this since it will motivate some important concepts. We’ll split the data into a train / test pair using the <strong>createDataPartition</strong> function from caret. We’ll go with an 80% / 20% split. You’ve seen this before with the linear modelling examples.</p>
<p><img src="pics/orr.png" width="500" /></p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb194-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">891</span>)</a>
<a class="sourceLine" id="cb194-2" data-line-number="2">idx &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(pm<span class="op">$</span>diabetes, <span class="dt">p=</span>.<span class="dv">80</span>, <span class="dt">list=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb194-3" data-line-number="3"></a>
<a class="sourceLine" id="cb194-4" data-line-number="4">glm_train &lt;-<span class="st"> </span>pm[idx,]</a>
<a class="sourceLine" id="cb194-5" data-line-number="5">glm_test  &lt;-<span class="st"> </span>pm[<span class="op">-</span>idx,]</a>
<a class="sourceLine" id="cb194-6" data-line-number="6"></a>
<a class="sourceLine" id="cb194-7" data-line-number="7">glm_model &lt;-<span class="st"> </span><span class="kw">glm</span>(diabetes <span class="op">~</span><span class="st"> </span>.,</a>
<a class="sourceLine" id="cb194-8" data-line-number="8">                 <span class="dt">data =</span> glm_train,</a>
<a class="sourceLine" id="cb194-9" data-line-number="9">                 <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb194-10" data-line-number="10"></a>
<a class="sourceLine" id="cb194-11" data-line-number="11"><span class="co"># Next well make some predictions using the test data</span></a>
<a class="sourceLine" id="cb194-12" data-line-number="12"></a>
<a class="sourceLine" id="cb194-13" data-line-number="13">glm_preds &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_model,</a>
<a class="sourceLine" id="cb194-14" data-line-number="14">                     glm_test,</a>
<a class="sourceLine" id="cb194-15" data-line-number="15">                     <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb194-16" data-line-number="16">glm_preds[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>]</a></code></pre></div>
<pre><code>##      2      6      8     22     23     30     33     36     38     40 
## 0.0584 0.1556 0.6721 0.3119 0.9306 0.2785 0.0573 0.1473 0.3932 0.5356</code></pre>
<p>What do we get back from our prediction ? These are probabilities that, for each row in the test data frame, represent the likelihood of that person being positive for diabetes.</p>
<p>The trick then is to figure out the threshold value (aka “alpha value”) over which we would classify the person as being positive for diabetes. Most people will generally pick 0.5:</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb196-1" data-line-number="1">pos_neg &lt;-<span class="st"> </span><span class="kw">ifelse</span>(glm_preds <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>,<span class="st">&quot;pos&quot;</span>,<span class="st">&quot;neg&quot;</span>)</a>
<a class="sourceLine" id="cb196-2" data-line-number="2"></a>
<a class="sourceLine" id="cb196-3" data-line-number="3"><span class="co"># Then they would compare this against the known data</span></a>
<a class="sourceLine" id="cb196-4" data-line-number="4">(my_conf &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="dt">predicted=</span>pos_neg,<span class="dt">actual=</span>glm_test<span class="op">$</span>diabetes))</a></code></pre></div>
<pre><code>##          actual
## predicted neg pos
##       neg  89  20
##       pos  11  33</code></pre>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" data-line-number="1"><span class="co"># Then they might use this table to compute an accuracy metric</span></a>
<a class="sourceLine" id="cb198-2" data-line-number="2">estimated_accuracy &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(my_conf))<span class="op">/</span><span class="kw">sum</span>(my_conf)</a>
<a class="sourceLine" id="cb198-3" data-line-number="3"></a>
<a class="sourceLine" id="cb198-4" data-line-number="4"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;Accuracy is&quot;</span>,<span class="kw">round</span>(estimated_accuracy,<span class="dv">2</span>)))</a></code></pre></div>
<pre><code>## [1] &quot;Accuracy is 0.8&quot;</code></pre>
<p>Is this okay ? Not really. To better address this question, we need to back up a bit and recall that we are dealing with a curve like the one below which is a sigmoid function. The idea is to take our probabilities, which range between 0 and 1, and then pick a threshold over which we would classify that person as being positive for diabetes.</p>
<p><img src="biosml_files/figure-html/logitplot-1.png" width="672" /></p>
</div>
<div id="selecting-the-correct-threshold-alpha" class="section level2">
<h2><span class="header-section-number">6.4</span> Selecting The Correct Threshold / Alpha</h2>
<p>The temptation is to select 0.5 as the threshold such that if a returned probability exceeds 0.5 then we classify the associated subject as being “positive” for the disease. But then this assumes that the probabilities are distributed perfectly. This is frequently <em>NOT</em> the case though it doesn’t stop people from using 0.5. Here is another view of the situation.</p>
<p><img src="pics/pc.png" /></p>
<p>The above represents a perfect classifier wherein we can cleanly distinguish between True Positives and Negatives. Note that, the cutoff point is at 0.5 which represents an ideal case. However, in most situations, what we have is something like this:</p>
<p><img src="pics/tnfp.png" /></p>
<div id="moving-the-threshold" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Moving The Threshold</h3>
<p>What happens if we move our threshold towards 0 ? We would definitely get more of the actual positive cases. What if we moved it to say 0.1 ? We would probably get ALL of the True Positives at the expense of getting a lot of False Positives.</p>
<p>What happens if we move our threshold towards 1 ? We would
definitely get more of the actual negative cases. What if we moved it to say 0.9 ? We would probably get ALL of the True Negatives at the expense of getting a lot of False Negatives.</p>
</div>
<div id="distribution-of-predicted-probabilities" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Distribution of Predicted Probabilities</h3>
<p>We might first wish to look at the distribution of the returned probabilities before making a decision about where to set the threshold. You should now be able to clearly that simply selecting 0.5 in a general case might not be the best approach.</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb200-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb200-2" data-line-number="2"><span class="kw">boxplot</span>(glm_preds, </a>
<a class="sourceLine" id="cb200-3" data-line-number="3">        <span class="dt">main=</span><span class="st">&quot;GLM Model Probabilities&quot;</span>)</a>
<a class="sourceLine" id="cb200-4" data-line-number="4"><span class="kw">grid</span>()</a>
<a class="sourceLine" id="cb200-5" data-line-number="5"><span class="kw">plot</span>(glm_preds[<span class="kw">order</span>(glm_preds)],<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,</a>
<a class="sourceLine" id="cb200-6" data-line-number="6">               <span class="dt">main=</span><span class="st">&quot;Prediction Probabilities&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;probability&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Patients&quot;</span>)</a>
<a class="sourceLine" id="cb200-7" data-line-number="7"><span class="kw">grid</span>()</a></code></pre></div>
<p><img src="biosml_files/figure-html/bxplotalpha-1.png" width="672" /></p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</a></code></pre></div>
<p>The median is somewhere around .25 so we could use that for now although we are just guessing.</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb202-1" data-line-number="1">glm_label_preds &lt;-<span class="st"> </span><span class="kw">ifelse</span>(glm_preds <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.25</span>,<span class="st">&quot;pos&quot;</span>,<span class="st">&quot;neg&quot;</span>)</a>
<a class="sourceLine" id="cb202-2" data-line-number="2"></a>
<a class="sourceLine" id="cb202-3" data-line-number="3"><span class="co"># We have to make the labels into a factor since</span></a>
<a class="sourceLine" id="cb202-4" data-line-number="4"><span class="co"># the diabetes column is a factor in the original data dset</span></a>
<a class="sourceLine" id="cb202-5" data-line-number="5"></a>
<a class="sourceLine" id="cb202-6" data-line-number="6">glm_label_preds &lt;-<span class="st"> </span><span class="kw">factor</span>(glm_label_preds, </a>
<a class="sourceLine" id="cb202-7" data-line-number="7">                         <span class="dt">levels =</span> <span class="kw">levels</span>(glm_test[[<span class="st">&quot;diabetes&quot;</span>]]))</a>
<a class="sourceLine" id="cb202-8" data-line-number="8">glm_label_preds[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>]</a></code></pre></div>
<pre><code>##   2   6   8  22  23  30  33  36  38  40 
## neg neg pos pos pos pos neg neg pos pos 
## Levels: neg pos</code></pre>
</div>
</div>
<div id="hypothesis-testing" class="section level2">
<h2><span class="header-section-number">6.5</span> Hypothesis Testing</h2>
<p>Now, before we dig into the details our classifier, remember that most things in statistics and classification revolves around the idea of a hypothesis. In this case, the “null” hypothesis is that a patient does NOT have the disease whereas the alternative hypothesis is that they do. Well, for a statistician that’s a bit strong. Let’s just say that if there is enough evidence to reject the null hypothesis then we will.</p>
<p>Anyway, the larger idea is that we might apply our test to someone and subsequently determine, by mistake, that they have a disease when in fact they don’t.</p>
<pre><code>- This would be an example of a &quot;false positive&quot; also known as a &quot;Type I Error&quot;.  </code></pre>
<p>It is also possible that we apply the test to someone and we say that the do not have the disease when they actually do.</p>
<pre><code>- This is known as a &quot;false negative&quot; also known as a Type II Error&quot; </code></pre>
<p>Here we fail to reject the null hypothesis for this person. A perfect test would have zero false positives and zero false negatives.</p>
<p><img src="pics/type2and1.png" /></p>
</div>
<div id="confusion-matrix" class="section level2">
<h2><span class="header-section-number">6.6</span> Confusion Matrix</h2>
<p>So now we have our predictions in terms of actual labels that we could then use to compare to the actual labels that are stored in the “diabetes” column of the test data frame. This table provides the basis for computing a number of performance measures such as accuracy, precision, sensitivity, specificity and others. In predictive modeling we are always interested in how well any given model will perform on “new” data.</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb206-1" data-line-number="1"><span class="co"># How does this compare to the truth ?</span></a>
<a class="sourceLine" id="cb206-2" data-line-number="2">my_confusion &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="dt">predicted =</span> glm_label_preds,</a>
<a class="sourceLine" id="cb206-3" data-line-number="3">                      <span class="dt">actual =</span> glm_test<span class="op">$</span>diabetes)</a>
<a class="sourceLine" id="cb206-4" data-line-number="4">my_confusion</a></code></pre></div>
<pre><code>##          actual
## predicted neg pos
##       neg  59   6
##       pos  41  47</code></pre>
<p>Let’s break this down since it is really important to know how to use this construct. First, we notice that there are N = 153 people in this study.</p>
<p><img src="pics/cm3.png" /></p>
<p><em>True Positives</em> - With respect to the second row - we predicted that 47 people have the disease that actually do have it. You could then say that the number of TRUE POSITIVES (abbreviated as “TP”) is 47.</p>
<p><em>False Positives</em> - We also predicted that 41 people have the condition when they in fact do not. We could then say that the number of FALSE POSITIVES, abbreviated as “FP”, is 41.</p>
<p><em>False Negatives</em> - In the first row we predicted that 6 people do NOT have the disease/condition when they actually do. So you could say that the number of FALSE NEGATIVES (abbreviated as FN) is 6.</p>
<p><em>True Negatives</em> - We also predicted that 59 people do not have the condition and they do not. So then the number of TRUE NEGATIVES (abbreviated as TN) is also 59.</p>
<div id="computing-performance-metrics" class="section level3">
<h3><span class="header-section-number">6.6.1</span> Computing Performance Metrics</h3>
<p>Now comes the fun part in that you might be concerned with specific metrics to assess the quality of your model in specific terms. Since our model, such as it is, seems to relate to the quality of a medical diagnostic we might be concerned with its accuracy, precision, and sensitivity.</p>
<p>The first two terms in particular are frequently used synonymously when they are not the same thing.Below is a graphic from Wikipedia which presents many (if not all) of the metrics that can be computed against a confusion matrix.</p>
<p><img src="pics/cmwiki.png" width="1200" /></p>
<p>We’ll focus on some specific metrics as they will assist our understanding of how to assess a model.</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb208-1" data-line-number="1">my_confusion</a></code></pre></div>
<pre><code>##          actual
## predicted neg pos
##       neg  59   6
##       pos  41  47</code></pre>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb210-1" data-line-number="1"><span class="kw">sum</span>(my_confusion)</a></code></pre></div>
<pre><code>## [1] 153</code></pre>
<div id="accuracy" class="section level4">
<h4><span class="header-section-number">6.6.1.1</span> Accuracy</h4>
<p>So let’s take the number of observed True Positives and True Negatives, add them together, and divide them by the total number of patients in the study group to arrive at what is known as the <strong>Accuracy</strong> of our model. Another way to think of the denominator is as the sum of all observed results, True and False.</p>
<p>Accuracy = (TP + TN) / (TP + TN + FP + FN) = (59 + 47)/153 = 0.69</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb212-1" data-line-number="1">accuracy &lt;-<span class="st"> </span>(my_confusion[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>my_confusion[<span class="dv">2</span>,<span class="dv">2</span>]) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(my_confusion)</a>
<a class="sourceLine" id="cb212-2" data-line-number="2">(accuracy <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(.,<span class="dv">2</span>))</a></code></pre></div>
<pre><code>## [1] 0.69</code></pre>
</div>
<div id="sensitivity" class="section level4">
<h4><span class="header-section-number">6.6.1.2</span> Sensitivity</h4>
<p>Sensitivity, also known as the True Positive rate, tells us how frequently we find a positive case given that it is actually positive. It is the number of True Positives (TP) divided by the sum of True Positives and False Negatives (which are actually Positives). This</p>
<p>Sensitivity = TP / (TP + FN) = 47 / (47 + 6) = 0.89</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb214-1" data-line-number="1">sensitivity &lt;-<span class="st"> </span>my_confusion[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">/</span>(my_confusion[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">+</span>my_confusion[<span class="dv">1</span>,<span class="dv">2</span>])</a>
<a class="sourceLine" id="cb214-2" data-line-number="2">sensitivity <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(.,<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 0.89</code></pre>
<p>Sensitivity also has the synonyms of “recall” and “hit rate” which might be referenced depending on your domain on interest.</p>
</div>
<div id="false-positive-rate" class="section level4">
<h4><span class="header-section-number">6.6.1.3</span> False Positive Rate</h4>
<p>Just as there is the True Positive Rate there is a False Positive Rate. This tells us how likely it is we will falsely reject the null hypothesis which is a Type I error.</p>
<p>False Positive Rate = FP / (FP + TN) = 41 / (41 + 59) = .41</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb216-1" data-line-number="1">fpr &lt;-<span class="st"> </span>my_confusion[<span class="dv">2</span>,<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>(my_confusion[<span class="dv">2</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>my_confusion[<span class="dv">1</span>,<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb216-2" data-line-number="2">(fpr <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(.,<span class="dv">2</span>))</a></code></pre></div>
<pre><code>## [1] 0.41</code></pre>
</div>
<div id="specificity" class="section level4">
<h4><span class="header-section-number">6.6.1.4</span> Specificity</h4>
<p>Specificity tells us how frequently we find a negative case given that it is actually negative. This is also known as the “True Negative Rate”</p>
<p>Specificity = TN / (TN + FP) = 59 / (59 + 41) = 0.59</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb218-1" data-line-number="1">specificity &lt;-<span class="st"> </span>my_confusion[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>(my_confusion[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">+</span><span class="st"> </span>my_confusion[<span class="dv">2</span>,<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb218-2" data-line-number="2">(specificity <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(.,<span class="dv">2</span>))</a></code></pre></div>
<pre><code>## [1] 0.59</code></pre>
</div>
<div id="precision" class="section level4">
<h4><span class="header-section-number">6.6.1.5</span> Precision</h4>
<p>How precise is the model ? Precision is a measure of the ability of a classification model to identify only the relevant data points. This is also known as Positive Predictive Value. We take the number of True Positives (TP) and divide that by the sum of True Positives (TP) and False Positives (FP). The denominator is the sum of row 2 in our matrix.</p>
<p>It is helpful to know that <strong>Precision</strong> is also known as the PPV “Positive Predictive Value” since it is concerned with the ratio of True Positives over the sum of all Positive related quantities including the False Positives. The larger the number of FP then the smaller the ratio which results in a lower precision.</p>
<p>Precision = TP / (TP + FP) = 47 / (47 + 41) = 0.53</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb220-1" data-line-number="1">precision &lt;-<span class="st"> </span>my_confusion[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">/</span>(my_confusion[<span class="dv">2</span>,<span class="dv">1</span>]<span class="op">+</span>my_confusion[<span class="dv">2</span>,<span class="dv">2</span>])</a>
<a class="sourceLine" id="cb220-2" data-line-number="2">precision <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(.,<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 0.53</code></pre>
</div>
</div>
</div>
<div id="picking-the-right-metric" class="section level2">
<h2><span class="header-section-number">6.7</span> Picking the Right Metric</h2>
<p>There are more ratios we could compute some of which might be more relevant to our classification issue. In reality, picking the “right” metric is a function of your domain of study. Frequently, the sensitivity and specificity are used in medical testing scenarios as is the false positive rate. But you should search the literature in your area of interest to determine what is commonly used. We could say much more about these metrics but we’ll keep it simple for now.</p>
<p>For now, we’ll use both the <em>True Positive Rate</em> and the <em>False Positive Rate</em>.</p>
</div>
<div id="wait.-where-are-we" class="section level2">
<h2><span class="header-section-number">6.8</span> Wait. Where Are We ?</h2>
<p>We’ve been doing a lot. We did the following:</p>
<ol style="list-style-type: decimal">
<li>Built a model against the training data</li>
<li>Used the model to make a prediction against the test data</li>
<li>Took the probabilities from Step #2 and</li>
<li>Selected a threshold / alpha value (e.g. .3) and</li>
<li>Decided that probabilities over that threshold would be “pos”</li>
<li>Created a table of outcomes (confusion matrix) to compare predictions vs reality</li>
<li>Computed some important ratios</li>
</ol>
<p>While this process was useful the resulting confusion matrix corresponded to just <em>ONE</em> particular threshold ? What if we had picked another value ? We would then get a different confusion matrix as well as different performance measures.</p>
<blockquote>
<p>In effect we would have to repeat steps 3-6 all over again for each threshold !!!</p>
</blockquote>
<p>Let’s find a way to generalize these steps. First, let’s create a function that allows us to compute the True Positive Rate (aka “Sensitivity”) and the False Positive Rate ( 1 - Specificity). If we apply it to our predictions from our example in progress, the output would be as follows.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb222-1" data-line-number="1">get_tprfpr &lt;-<span class="st"> </span><span class="cf">function</span>(pred,true) {</a>
<a class="sourceLine" id="cb222-2" data-line-number="2">  myt &lt;-<span class="st"> </span><span class="kw">table</span>(pred,true)</a>
<a class="sourceLine" id="cb222-3" data-line-number="3">  tpr &lt;-<span class="st"> </span>myt[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">/</span>(myt[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">+</span>myt[<span class="dv">1</span>,<span class="dv">2</span>])</a>
<a class="sourceLine" id="cb222-4" data-line-number="4">  fpr &lt;-<span class="st"> </span>myt[<span class="dv">2</span>,<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>(myt[<span class="dv">2</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>myt[<span class="dv">1</span>,<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb222-5" data-line-number="5">  <span class="kw">return</span>(<span class="kw">c</span>(<span class="dt">tpr=</span>tpr,<span class="dt">fpr=</span>fpr))</a>
<a class="sourceLine" id="cb222-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb222-7" data-line-number="7"></a>
<a class="sourceLine" id="cb222-8" data-line-number="8"><span class="kw">get_tprfpr</span>(glm_label_preds,glm_test<span class="op">$</span>diabetes)</a></code></pre></div>
<pre><code>##   tpr   fpr 
## 0.887 0.410</code></pre>
<p>We could now use this function to compute these metrics for any set of predictions vs actual outcomes. We could generalize this function to accept an alpha so we could explore the full probability domain (0 - 1) and then plot the TPR vs FPR. This is, in effect, creating something known as a ROC Curve aka Receiver Operating Characteristic Curve.</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb224-1" data-line-number="1">get_tprfpr &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">thresh=</span>.<span class="dv">25</span>,<span class="dt">probs=</span>glm_preds) {</a>
<a class="sourceLine" id="cb224-2" data-line-number="2">  diabetes &lt;-<span class="st"> </span><span class="kw">ifelse</span>(probs <span class="op">&gt;</span><span class="st"> </span>thresh,<span class="st">&quot;pos&quot;</span>,<span class="st">&quot;neg&quot;</span>)</a>
<a class="sourceLine" id="cb224-3" data-line-number="3">  myt &lt;-<span class="st"> </span><span class="kw">table</span>(diabetes,glm_test<span class="op">$</span>diabetes)</a>
<a class="sourceLine" id="cb224-4" data-line-number="4">  tpr &lt;-<span class="st"> </span>myt[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">/</span>(myt[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">+</span>myt[<span class="dv">1</span>,<span class="dv">2</span>])</a>
<a class="sourceLine" id="cb224-5" data-line-number="5">  fpr &lt;-<span class="st"> </span>myt[<span class="dv">2</span>,<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>(myt[<span class="dv">2</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>myt[<span class="dv">1</span>,<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb224-6" data-line-number="6">  <span class="kw">return</span>(<span class="kw">c</span>(<span class="dt">tpr=</span>tpr,<span class="dt">fpr=</span>fpr,<span class="dt">alpha=</span>thresh))</a>
<a class="sourceLine" id="cb224-7" data-line-number="7">}</a></code></pre></div>
<p>Let’s look at a sequence of alpha values:</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb225-1" data-line-number="1">metrics &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(<span class="kw">seq</span>(<span class="fl">0.01</span>,.<span class="dv">95</span>,.<span class="dv">09</span>),<span class="cf">function</span>(x) <span class="kw">get_tprfpr</span>(x))) </a>
<a class="sourceLine" id="cb225-2" data-line-number="2"><span class="kw">plot</span>(tpr<span class="op">~</span>fpr,metrics,</a>
<a class="sourceLine" id="cb225-3" data-line-number="3">     <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),</a>
<a class="sourceLine" id="cb225-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;Steve&#39;s Super Cool ROC Curve&quot;</span>,</a>
<a class="sourceLine" id="cb225-5" data-line-number="5">     <span class="dt">xlab=</span><span class="st">&quot;False Positve Rate (1-Specificity)&quot;</span>,</a>
<a class="sourceLine" id="cb225-6" data-line-number="6">     <span class="dt">ylab=</span><span class="st">&quot;True Positive Rate&quot;</span>,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>)</a>
<a class="sourceLine" id="cb225-7" data-line-number="7"><span class="kw">grid</span>()</a>
<a class="sourceLine" id="cb225-8" data-line-number="8"><span class="kw">abline</span>(<span class="dt">a=</span><span class="dv">0</span>, <span class="dt">b=</span><span class="dv">1</span>,<span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb225-9" data-line-number="9"></a>
<a class="sourceLine" id="cb225-10" data-line-number="10"><span class="co"># Put the associated threshold values on the plot to help you identify</span></a>
<a class="sourceLine" id="cb225-11" data-line-number="11"><span class="co"># the right value to maximize the AUC (Area Under Curve)</span></a>
<a class="sourceLine" id="cb225-12" data-line-number="12"></a>
<a class="sourceLine" id="cb225-13" data-line-number="13"><span class="kw">text</span>(metrics[,<span class="dv">2</span>],metrics[,<span class="dv">1</span>],<span class="dt">labels=</span>metrics[,<span class="dv">3</span>],<span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<p><img src="biosml_files/figure-html/metrtpr-1.png" width="672" /></p>
<p>It turns out that area under an ROC curve is a measure of the usefulness of a test in general, where a greater area means a more useful test. Ideally we would want the area under the curve (also known as “AUC”) to be as close to 1 as possible. The dashed line above represents a classifier that basically “guesses” the outcome (pos vs neg) using a “coin flip” mentality.</p>
<p>In case you are wondering, there is a command in R which will make the curve for you. We need to use the prediction PROBABILITES as part of the call to the colAUC function. We also pass in the actual labels for comparison.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb226-1" data-line-number="1"><span class="co"># Use the colAUC function from the caTools package</span></a>
<a class="sourceLine" id="cb226-2" data-line-number="2"></a>
<a class="sourceLine" id="cb226-3" data-line-number="3">pm_model_glm_probs &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_model,glm_test,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb226-4" data-line-number="4">caTools<span class="op">::</span><span class="kw">colAUC</span>(pm_model_glm_probs,glm_test<span class="op">$</span>diabetes,<span class="dt">plotROC=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="biosml_files/figure-html/carocagain-1.png" width="672" /></p>
<pre><code>##              [,1]
## neg vs. pos 0.868</code></pre>
<p>Here are some more examples of general curves including one that is “perfect”. B and C are okay where as D represents mere guessing.</p>
<p><img src="pics/multirocs.png" /></p>
<p>Here is another view of determining how good a ROC curve is:</p>
<p><img src="biosml_files/figure-html/classroc-1.png" width="672" /></p>
<p>So, our classifier does better than that but certainly not perfectly. Now, we also care about the threshold that gives us a good balance between the TPR and FPR. I mean if we wanted a max AUC with no other concerns, we would also be accepting a very high FPR. So this is why looking at the curve is useful.</p>
</div>
<div id="other-ways-to-compute-the-roc-curve" class="section level2">
<h2><span class="header-section-number">6.9</span> Other Ways To Compute The ROC Curve</h2>
<p>So by now your head might be reeling from all the details and tedium associated with selecting alpha values, computing matrices, and plotting ROC curves though I it should be no surprise that R (as well as Python) has a number of functions that can compute these things for you.</p>
<p>As an example, if we wanted to plot the ROC curve we generated by hand we could use the ROCR package. It takes the probabilities returned by our first prediction object as well as the known labels in the glm_test data frame.</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb228-1" data-line-number="1"><span class="kw">library</span>(ROCR)</a>
<a class="sourceLine" id="cb228-2" data-line-number="2">pred &lt;-<span class="st"> </span>ROCR<span class="op">::</span><span class="kw">prediction</span>(<span class="dt">predictions =</span> glm_preds,</a>
<a class="sourceLine" id="cb228-3" data-line-number="3">                         <span class="dt">labels =</span> glm_test<span class="op">$</span>diabetes)</a>
<a class="sourceLine" id="cb228-4" data-line-number="4"></a>
<a class="sourceLine" id="cb228-5" data-line-number="5">perf &lt;-<span class="st"> </span>ROCR<span class="op">::</span><span class="kw">performance</span>(pred,</a>
<a class="sourceLine" id="cb228-6" data-line-number="6">                    <span class="st">&quot;tpr&quot;</span>,</a>
<a class="sourceLine" id="cb228-7" data-line-number="7">                    <span class="st">&quot;fpr&quot;</span>)</a>
<a class="sourceLine" id="cb228-8" data-line-number="8">ROCR<span class="op">::</span><span class="kw">plot</span>(perf,<span class="dt">colorize=</span>T,</a>
<a class="sourceLine" id="cb228-9" data-line-number="9">     <span class="dt">print.cutoffs.at=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="fl">0.1</span>),</a>
<a class="sourceLine" id="cb228-10" data-line-number="10">     <span class="dt">lwd=</span><span class="dv">3</span>,<span class="dt">las=</span><span class="dv">1</span>,<span class="dt">main=</span><span class="st">&quot;A Pretty ROC Curve&quot;</span>)</a>
<a class="sourceLine" id="cb228-11" data-line-number="11"><span class="kw">abline</span>(<span class="dt">a =</span> <span class="dv">0</span>, <span class="dt">b =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb228-12" data-line-number="12"></a>
<a class="sourceLine" id="cb228-13" data-line-number="13"><span class="kw">grid</span>()</a></code></pre></div>
<p><img src="biosml_files/figure-html/ROCR1-1.png" width="672" /></p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb229-1" data-line-number="1"><span class="co"># Get the optimal AUC</span></a>
<a class="sourceLine" id="cb229-2" data-line-number="2"></a>
<a class="sourceLine" id="cb229-3" data-line-number="3">auc_ROCR &lt;-<span class="st"> </span>ROCR<span class="op">::</span><span class="kw">performance</span>(pred,<span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)</a>
<a class="sourceLine" id="cb229-4" data-line-number="4">auc_ROCR &lt;-<span class="st"> </span>auc_ROCR<span class="op">@</span>y.values[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb229-5" data-line-number="5"><span class="kw">cat</span>(<span class="st">&quot;Optimal AUC is: &quot;</span>,auc_ROCR,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</a></code></pre></div>
<pre><code>## Optimal AUC is:  0.868</code></pre>
<p>And if we wanted to see the auc associated with the “optimal” alpha we could use some functions to get that for us:</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb231-1" data-line-number="1">pm_model_glm_probs &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_model,glm_test,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb231-2" data-line-number="2">myRoc &lt;-<span class="st"> </span>pROC<span class="op">::</span><span class="kw">roc</span>(diabetes<span class="op">~</span>pm_model_glm_probs,</a>
<a class="sourceLine" id="cb231-3" data-line-number="3">                   <span class="dt">auc=</span><span class="ot">TRUE</span>,<span class="dt">data=</span>glm_test)</a>
<a class="sourceLine" id="cb231-4" data-line-number="4"></a>
<a class="sourceLine" id="cb231-5" data-line-number="5">pROC<span class="op">::</span><span class="kw">coords</span>(myRoc, <span class="st">&quot;best&quot;</span>, <span class="dt">ret =</span> <span class="st">&quot;threshold&quot;</span>,<span class="dt">transpose =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## threshold 
##     0.385</code></pre>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb233-1" data-line-number="1"><span class="kw">get_tprfpr</span>(.<span class="dv">3850002</span>)</a></code></pre></div>
<pre><code>##   tpr   fpr alpha 
## 0.774 0.160 0.385</code></pre>
<p>And while I’m at it, I might as well show you how easy it is to compute a confusion matrix corresponding to the ideal threshold.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb235-1" data-line-number="1">glm_label_preds &lt;-<span class="st"> </span><span class="kw">ifelse</span>(glm_preds <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.385</span>,<span class="st">&quot;pos&quot;</span>,<span class="st">&quot;neg&quot;</span>)</a>
<a class="sourceLine" id="cb235-2" data-line-number="2"></a>
<a class="sourceLine" id="cb235-3" data-line-number="3"><span class="co"># We have to make the labels into a factor since</span></a>
<a class="sourceLine" id="cb235-4" data-line-number="4"><span class="co"># the diabetes column is a factor in the original data dset</span></a>
<a class="sourceLine" id="cb235-5" data-line-number="5"></a>
<a class="sourceLine" id="cb235-6" data-line-number="6">glm_label_preds &lt;-<span class="st"> </span><span class="kw">factor</span>(glm_label_preds, </a>
<a class="sourceLine" id="cb235-7" data-line-number="7">                         <span class="dt">levels =</span> <span class="kw">levels</span>(glm_test[[<span class="st">&quot;diabetes&quot;</span>]]))</a></code></pre></div>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb236-1" data-line-number="1"><span class="co"># How does this compare to the truth ?</span></a>
<a class="sourceLine" id="cb236-2" data-line-number="2">my_confusion &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="dt">predicted =</span> glm_label_preds,</a>
<a class="sourceLine" id="cb236-3" data-line-number="3">                      <span class="dt">actual =</span> glm_test<span class="op">$</span>diabetes)</a></code></pre></div>
<p>We could use a function from the <strong>caret</strong> package called <strong>confusionMatrix</strong> to show us the relevant metrics. Much better than doing it by hand.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb237-1" data-line-number="1">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(my_confusion,<span class="dt">positive=</span><span class="st">&quot;pos&quot;</span>)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##          actual
## predicted neg pos
##       neg  84  12
##       pos  16  41
##                                         
##                Accuracy : 0.817         
##                  95% CI : (0.746, 0.875)
##     No Information Rate : 0.654         
##     P-Value [Acc &gt; NIR] : 6.2e-06       
##                                         
##                   Kappa : 0.603         
##                                         
##  Mcnemar&#39;s Test P-Value : 0.571         
##                                         
##             Sensitivity : 0.774         
##             Specificity : 0.840         
##          Pos Pred Value : 0.719         
##          Neg Pred Value : 0.875         
##              Prevalence : 0.346         
##          Detection Rate : 0.268         
##    Detection Prevalence : 0.373         
##       Balanced Accuracy : 0.807         
##                                         
##        &#39;Positive&#39; Class : pos           
## </code></pre>
<p>We could also work directly with our labelled predictions and known labels.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb239-1" data-line-number="1">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(glm_label_preds,</a>
<a class="sourceLine" id="cb239-2" data-line-number="2">                       glm_test<span class="op">$</span>diabetes,<span class="dt">positive=</span><span class="st">&quot;pos&quot;</span>)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction neg pos
##        neg  84  12
##        pos  16  41
##                                         
##                Accuracy : 0.817         
##                  95% CI : (0.746, 0.875)
##     No Information Rate : 0.654         
##     P-Value [Acc &gt; NIR] : 6.2e-06       
##                                         
##                   Kappa : 0.603         
##                                         
##  Mcnemar&#39;s Test P-Value : 0.571         
##                                         
##             Sensitivity : 0.774         
##             Specificity : 0.840         
##          Pos Pred Value : 0.719         
##          Neg Pred Value : 0.875         
##              Prevalence : 0.346         
##          Detection Rate : 0.268         
##    Detection Prevalence : 0.373         
##       Balanced Accuracy : 0.807         
##                                         
##        &#39;Positive&#39; Class : pos           
## </code></pre>
</div>
<div id="roc-curve-summary" class="section level2">
<h2><span class="header-section-number">6.10</span> ROC Curve Summary</h2>
<p>The above can be confusing although what you will soon discover is that being able to compute the AUC (Area Under Curve) will be sufficient to judge the quality of a model - well in general it’s a good start. The <strong>caret</strong> package can do that for you so you don’t need to use the various functions about to find that.</p>
<p>You might want to put up a ROC curve based on some predictions in which case you would still need to use one of the above functions. If you just want to see a basic ROC Curve then take this approach which will give you both the AUC and a ROC Curve albeit it much less “pretty” than the one above.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="caret-package.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classification-example.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
